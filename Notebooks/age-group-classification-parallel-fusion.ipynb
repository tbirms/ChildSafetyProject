{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Age Group Classification using Multiple Touchscreen Gestures**\n",
    "\n",
    "### Child Safety Project\n",
    "\n",
    "Tom Birmingham & Dr. Hossain, Southern CT State University, Computer Science Department, New Haven, CT\n",
    "\n",
    "![University Banner](<https://clubrunner.blob.core.windows.net/00000400324/EventImages/951e9035-3850-4f27-99d4-5a5d4bd17430-southern-connecticut-state-university(1).jpg>)\n",
    "\n",
    "photo: [connecticut.csteachers.org](https://connecticut.csteachers.org/events/chapter-meeting-november-2019-southern-connecticut-state-university)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook represents the thesis work of graduate student Thomas Birmingham under the advisement of Dr. Hossain, Southern Connecticut State University (SCSU) Computer Science Department.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The purpose of the project is to further the state-of-the-art in age group classification using multiple touchscreen gestures and parallel fusion. Previous methods for classifying users (as child, teen, or adult) have been performed by other students in the project with Tap, Zoom, and Swipe gestures using machine learning. In order to further the state-of-the-art, this project will combine gestures using three types of parallel fusion to determine the most effective method for age group classification using multiple touchscreen gestures.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "In order to determine the most effective method of parallel fusion for age classification, we must first obtain the same or better results of classification using features of each gesture Swipe, Zoom, and Tap. After classificiton of each gesture is completed, classification with parallel fusion will be performed at the feature level, score level, and decision level. The performance of each level of fusion will be assessed to determine the most effective method for age group classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created on Apple M3 Max with 36 GB of memory. Not everyone has access to these computerers so this notebook can be made to run on Google Colab as well, where students can access shared compute resources with large amounts of RAM. This project has also been reviewed for memory optimization to reduce the amount of memory required to run these notebooks. For example, after loading the Child Safety Dataset, a Python object for each gesture is created as a Pandas Dataframes and exported to the /Checkpoints directory as a Python \"pickle\" file. Working from /Checkpoints allows users to resume their work without the time or space complexity of working with the raw dataset. You can check how much memory is available on your current runtime by running the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 36.0 GB of available RAM\n",
      "\n",
      "This is considered a high-RAM runtime\n"
     ]
    }
   ],
   "source": [
    "# check available memory\n",
    "from psutil import virtual_memory\n",
    "\n",
    "def print_available_memory():\n",
    "    ram_gb = virtual_memory().total / 1024**3\n",
    "    print('Your runtime has {:.1f} GB of available RAM\\n'.format(ram_gb))\n",
    "    if ram_gb < 20:\n",
    "        print('This is not considered a high-RAM runtime')\n",
    "    else:\n",
    "        print('This is considered a high-RAM runtime')\n",
    "\n",
    "print_available_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Any variable **not** contained within a fuction is treated as a global variable. In the above code block, notice the variable `ram_gb` is contained within the function `print_available_memory()`. Variables that are contained within a function do not persist after the function has been called. Variables outside of functions are treated as global variables, will persist, and use available memory. While you work with this notebook, try not to use variables outside of function definitions unless they are needed. You can check what variables are in memory and their size in bytes using the following code block: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable\tsize (bytes)\n",
      "--------\t------------\n",
      "old_tap_df \t 69211277\n",
      "tap_df \t 69211277\n",
      "session_df \t 90447\n",
      "user_df \t 39910\n",
      "\n",
      "TOTAL:\t\t135308.3 KB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "initial_vars = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith(\n",
    "    '_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "total = 0\n",
    "print(f\"variable\\tsize (bytes)\")\n",
    "print(f\"--------\\t------------\")\n",
    "for (var, size) in initial_vars:\n",
    "    total = total + size\n",
    "    if (size > 160 and var not in [\"initial_vars\", \"total\"]):\n",
    "        print(var, '\\t', size)\n",
    "print(f\"\\nTOTAL:\\t\\t{total/1024:.1f} KB\")\n",
    "\n",
    "del ipython_vars, initial_vars, var, size, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell at any time to show what variables are used in memory and the total amount of memory used by these . Unused variables can be removed with the `del` keyword followed by the variable. Remove them after the cell where they are no longer used!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "def load_dataframe(df_name):\n",
    "    filepath = os.path.join(\"Checkpoints\", f\"{df_name}.pkl\")\n",
    "    if os.path.exists(filepath):\n",
    "\n",
    "        with open(filepath, 'rb') as input:\n",
    "            df = pd.read_pickle(input)\n",
    "            print(f\"Loaded {df_name} from {filepath}\")\n",
    "            return df\n",
    "    else:\n",
    "        print(f\"File {filepath} does not exist.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_dataframe(df):\n",
    "    # Create the Checkpoints directory if it doesn't exist\n",
    "    checkpoints_dir = 'Checkpoints'\n",
    "    if not os.path.exists(checkpoints_dir):\n",
    "        os.makedirs(checkpoints_dir)\n",
    "    \n",
    "    # Get the variable name of the DataFrame dynamically\n",
    "    frame = inspect.currentframe().f_back\n",
    "    variable_name = None\n",
    "    for name, value in frame.f_locals.items():\n",
    "        if value is df:\n",
    "            variable_name = name\n",
    "            break\n",
    "\n",
    "    if variable_name is None:\n",
    "        raise ValueError(\"Could not determine the variable name of the DataFrame.\")\n",
    "    \n",
    "    # Create the file path\n",
    "    file_path = os.path.join(checkpoints_dir, f\"{variable_name}.pkl\")\n",
    "\n",
    "    # Save the DataFrame as a pickle file\n",
    "    with open(file_path, 'wb') as output:\n",
    "        pickle.dump(df, output)\n",
    "        print(f\"DataFrame saved as {file_path}\")\n",
    "    \n",
    "\n",
    "def get_dataset_files():\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print(\"Using Google Colab hosted runtime\")\n",
    "        files = get_dataset_files_from_google_drive()\n",
    "    else:\n",
    "        print(\"Using local runtime\")\n",
    "        files = get_dataset_files_locally()\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_dataset_files_from_google_drive():\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "    # Create Symbolic Links to directories 'Child_Safety_Data' and 'Checkpoints'\n",
    "    ! ln -s \"/content/drive/MyDrive/Child Safety Project/Child_Safety_Data\"\n",
    "    ! ln -s \"/content/drive/MyDrive/Child Safety Project/Checkpoints\"\n",
    "\n",
    "    # Get files in Child_Safety_Data and output total number of files\n",
    "    files = glob(r'Child_Safety_Data/**/*.txt', recursive=True)\n",
    "    print(\"Total Files:\", len(files))\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_dataset_files_locally():\n",
    "    files = glob(r'../Dataset/Child_Safety_Data/**/*.txt', recursive=True)\n",
    "    print(\"Total Files:\", len(files))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Users (user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded user_df from Checkpoints/user_df.pkl\n"
     ]
    }
   ],
   "source": [
    "def get_user_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    user_df = load_dataframe(\"user_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (user_df is None):\n",
    "        user_df = build_user_df()\n",
    "        save_dataframe(user_df)\n",
    "\n",
    "    return user_df\n",
    "\n",
    "\n",
    "def build_user_df():\n",
    "\n",
    "    user_file_dfs = list() # a list of dataframes, one user for each file in the dataset, to be concatenated into a single dataframe, user_df\n",
    "\n",
    "    for file in get_dataset_files():\n",
    "\n",
    "        filename = file.split('/')[-1]\n",
    "        if \"mod0\" in filename:\n",
    "\n",
    "            with open(file) as file:\n",
    "\n",
    "                # user data to extract from each file\n",
    "                user_id = ''\n",
    "                researcher = ''\n",
    "                grade = ''\n",
    "                gender = ''\n",
    "                age = ''\n",
    "                teacher = ''\n",
    "\n",
    "                # researcher\n",
    "                if filename[0] == '_':\n",
    "                    researcher = 'Carl'\n",
    "                elif filename[0] != '_':\n",
    "                    researcher = 'Kate'\n",
    "\n",
    "                # get data from file\n",
    "                for line in file:\n",
    "\n",
    "                    # collect key value pairs from file\n",
    "                    if \"=\" in line:\n",
    "                        key, value = line.strip().split(\"=\")\n",
    "                        \n",
    "                        key = key.lower()\n",
    "                        if key == \"grade\":\n",
    "                            grade = value\n",
    "                        elif key == \"gender\" or key == \"student\":\n",
    "                            gender = value\n",
    "                        elif key == \"age\" or key == \"studentage\":\n",
    "                            age = value\n",
    "                        elif key == \"teacher\":\n",
    "                            teacher = value\n",
    "\n",
    "                # User Unique Identifiers\n",
    "                if researcher == 'Carl':\n",
    "                    user_id = filename.split('_')[1]\n",
    "                elif researcher == 'Kate':\n",
    "                    user_id = teacher + grade + gender + age\n",
    "\n",
    "                # Note: Kate had recorded data differently than Carl\n",
    "                # where Carl collected datetime, session number, machine name, grade,\n",
    "                # gender, age, middle initial, birth month, and birth day\n",
    "                # and Kate collected datetime, session number, machine name, teacher,\n",
    "                # grade, gender, and age.\n",
    "                # Carl generated and assigned a unique identifier to each study participant,\n",
    "                # but we do not have a unique identifier for each of Kate's participant.\n",
    "                # We try to generate as unique an identifier as possible using a combination of\n",
    "                # teacher, grade, gender, and age, but there are duplicate user ids and\n",
    "                # therefore we cannot use all this data.\n",
    "\n",
    "                # create user dataframe for each file and append it to a list\n",
    "                user_data = {}\n",
    "                user_data['user_id'] = user_id\n",
    "                user_data['age'] = age\n",
    "                user_data['grade'] = grade\n",
    "                user_data['gender'] = gender\n",
    "                user_data['researcher'] = researcher\n",
    "                user_file_df = pd.DataFrame(user_data, index=[0])\n",
    "                user_file_dfs.append(user_file_df)\n",
    "    \n",
    "    # concatenate dataframes of user data into a single dataframe\n",
    "    user_df = pd.concat(user_file_dfs)\n",
    "\n",
    "    # remove dupliate user ids from kate\n",
    "    is_duplicate_kate = (user_df['researcher'] == 'Kate') & user_df.duplicated(subset='user_id', keep=False)\n",
    "    user_df = user_df[~is_duplicate_kate | (user_df['researcher'] != 'Kate')]\n",
    "\n",
    "    # Keep first user_id from Carl\n",
    "    user_df = user_df.drop_duplicates(subset='user_id', keep='first')\n",
    "\n",
    "    # reset indexes\n",
    "    user_df = user_df.reset_index(drop=True)\n",
    "\n",
    "    # set data types\n",
    "    user_df['age'] = user_df['age'].astype(int)\n",
    "    user_df['grade'] = user_df['grade'].astype(int)\n",
    "\n",
    "    # add age group\n",
    "    user_df['age_group'] = user_df['age'].apply(get_age_group)\n",
    "\n",
    "    return user_df\n",
    "\n",
    "\n",
    "def get_age_group(age):\n",
    "    if age < 13:\n",
    "        return 'child'\n",
    "    elif age < 18:\n",
    "        return 'teen'\n",
    "    else:\n",
    "        return 'adult'\n",
    "\n",
    "\n",
    "# return user_df as global variable\n",
    "user_df = get_user_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>grade</th>\n",
       "      <th>gender</th>\n",
       "      <th>researcher</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14S0915</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>M</td>\n",
       "      <td>Carl</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14T1227</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>M</td>\n",
       "      <td>Carl</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEVOLIS12M18</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>M</td>\n",
       "      <td>Kate</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROY12M17</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>M</td>\n",
       "      <td>Kate</td>\n",
       "      <td>teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REGAN12F17</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>F</td>\n",
       "      <td>Kate</td>\n",
       "      <td>teen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  age  grade gender researcher age_group\n",
       "0       14S0915   18     14      M       Carl     adult\n",
       "1       14T1227   19     14      M       Carl     adult\n",
       "2  NEVOLIS12M18   18     12      M       Kate     adult\n",
       "3      ROY12M17   17     12      M       Kate      teen\n",
       "4    REGAN12F17   17     12      F       Kate      teen"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sessions (session_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded session_df from Checkpoints/session_df.pkl\n"
     ]
    }
   ],
   "source": [
    "def get_session_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    session_df = load_dataframe(\"session_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (session_df is None):\n",
    "        session_df = build_session_df()\n",
    "        save_dataframe(session_df)\n",
    "\n",
    "    return session_df\n",
    "\n",
    "\n",
    "def build_session_df():\n",
    "    print(\"Building session_df from data\")\n",
    "\n",
    "    session_file_dfs = list() # a list of dataframes, one session for each file in the dataset, to be concatenated into a single dataframe, user_df\n",
    "\n",
    "    for file in get_dataset_files():\n",
    "\n",
    "        filename = file.split('/')[-1]\n",
    "\n",
    "        if \"mod0\" in filename:\n",
    "\n",
    "            with open(file) as file:\n",
    "\n",
    "                # expected data in file\n",
    "                session_id = ''\n",
    "                user_id = ''\n",
    "                researcher = ''\n",
    "                datetime = ''\n",
    "                device = ''\n",
    "                device_type = ''\n",
    "                session = ''\n",
    "                grade = ''\n",
    "                gender = ''\n",
    "                age = ''\n",
    "                teacher = ''\n",
    "\n",
    "                # researcher\n",
    "                if filename[0] == '_':\n",
    "                    researcher = 'Carl'\n",
    "                elif filename[0] != '_':\n",
    "                    researcher = 'Kate'\n",
    "\n",
    "                # get data from file\n",
    "                for line in file:\n",
    "                    if \"=\" in line:\n",
    "\n",
    "                        # collect key value pairs from file\n",
    "                        key, value = line.strip().split(\"=\")\n",
    "                        key = key.lower()\n",
    "                        if key == \"colldatetime\":\n",
    "                            datetime = value\n",
    "                        elif key == \"machname\":\n",
    "                            device = value\n",
    "                        elif key == \"session\":\n",
    "                            session = value\n",
    "                        elif key == \"grade\":\n",
    "                            grade = value\n",
    "                        elif key == \"gender\" or key == \"student\":\n",
    "                            gender = value\n",
    "                        elif key == \"age\" or key == \"studentage\":\n",
    "                            age = value\n",
    "                        elif key == \"teacher\":\n",
    "                            teacher = value\n",
    "\n",
    "                session_id = device + \"_\" + session\n",
    "\n",
    "                # User Unique Identifiers\n",
    "                if researcher == 'Carl':\n",
    "                    user_id = filename.split('_')[1]\n",
    "                elif researcher == 'Kate':\n",
    "                    user_id = teacher + grade + gender + age\n",
    "\n",
    "                # Device Type\n",
    "                if 'm' in device:\n",
    "                    device_type = 'tablet'\n",
    "                elif 'p' in device:\n",
    "                    device_type = 'phone'\n",
    "\n",
    "                # create session dataframe for each file and append it to a list\n",
    "                session_data = {}\n",
    "                session_data['session_id'] = session_id\n",
    "                session_data['user_id'] = user_id\n",
    "                session_data['datatime'] = datetime\n",
    "                session_data['device'] = device\n",
    "                session_data['session'] = session\n",
    "                session_data['device_type'] = device_type\n",
    "                session_file_df = pd.DataFrame(session_data, index=[0])\n",
    "                session_file_dfs.append(session_file_df)\n",
    "\n",
    "    # Create Session DataFrame\n",
    "    session_df = pd.concat(session_file_dfs)\n",
    "\n",
    "    # Drop sessions from session dataframe where there is not a unique user id\n",
    "    print(\"Removing sessions where there is not a unique user id...\")\n",
    "    unique_user_ids = get_user_df()['user_id'].unique()\n",
    "    mask = session_df['user_id'].isin(unique_user_ids)\n",
    "    session_df = session_df[mask]\n",
    "\n",
    "    # reset index\n",
    "    session_df = session_df.reset_index(drop=True)\n",
    "\n",
    "    return session_df\n",
    "\n",
    "\n",
    "# return session_df as global variable\n",
    "session_df = get_session_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>datatime</th>\n",
       "      <th>device</th>\n",
       "      <th>session</th>\n",
       "      <th>device_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p2_29</td>\n",
       "      <td>14S0915</td>\n",
       "      <td>Wed  2019-9-04  07:28</td>\n",
       "      <td>p2</td>\n",
       "      <td>29</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p7_38</td>\n",
       "      <td>14T1227</td>\n",
       "      <td>Wed  2019-8-28  07:28</td>\n",
       "      <td>p7</td>\n",
       "      <td>38</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p3_12</td>\n",
       "      <td>NEVOLIS12M18</td>\n",
       "      <td>Fri  2019-2-01  10:48</td>\n",
       "      <td>p3</td>\n",
       "      <td>12</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p7_8</td>\n",
       "      <td>ROY12M17</td>\n",
       "      <td>Thu  2019-1-31  11:59</td>\n",
       "      <td>p7</td>\n",
       "      <td>8</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1_17</td>\n",
       "      <td>REGAN12F17</td>\n",
       "      <td>Wed  2019-2-06  11:12</td>\n",
       "      <td>p1</td>\n",
       "      <td>17</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  session_id       user_id               datatime device session device_type\n",
       "0      p2_29       14S0915  Wed  2019-9-04  07:28     p2      29       phone\n",
       "1      p7_38       14T1227  Wed  2019-8-28  07:28     p7      38       phone\n",
       "2      p3_12  NEVOLIS12M18  Fri  2019-2-01  10:48     p3      12       phone\n",
       "3       p7_8      ROY12M17  Thu  2019-1-31  11:59     p7       8       phone\n",
       "4      p1_17    REGAN12F17  Wed  2019-2-06  11:12     p1      17       phone"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Tap Data (tap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tap_df from Checkpoints/tap_df.pkl\n"
     ]
    }
   ],
   "source": [
    "def get_tap_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    tap_df = load_dataframe(\"tap_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (tap_df is None):\n",
    "        tap_df = build_tap_df()\n",
    "        save_dataframe(tap_df)\n",
    "\n",
    "    return tap_df\n",
    "\n",
    "\n",
    "def build_tap_df():\n",
    "    print(\"Building tap_df...\")\n",
    "    \n",
    "    # Initialize Data Structures\n",
    "    file_df = pd.DataFrame()\n",
    "    file_dfs = list()\n",
    "    tap_df = pd.DataFrame()\n",
    "    session_df = get_session_df()\n",
    "\n",
    "    for file in get_dataset_files():\n",
    "\n",
    "        # get filename\n",
    "        filename = file.split('/')[-1]\n",
    "\n",
    "        # get session id\n",
    "        session_id = filename.split('_')[-4] + '_' + filename.split('_')[-3]\n",
    "\n",
    "        # Process mod5 (tap) files if session captured\n",
    "        if ('mod5' in filename) and (session_id in session_df['session_id'].unique()):\n",
    "\n",
    "            with open(file) as file:\n",
    "\n",
    "                fileDictionary = {}\n",
    "\n",
    "                for line in file:\n",
    "                    line = line.strip()\n",
    "\n",
    "                    if line:\n",
    "                        # Add key and value list to dictionary\n",
    "                        if \":\" in line:\n",
    "                            # split the line into key and values\n",
    "                            key, values = line.split(': ')\n",
    "                            # split values into list\n",
    "                            values = values.split(' ')\n",
    "                            # add the key-value pair to the dictionary\n",
    "                            fileDictionary[key] = values\n",
    "\n",
    "                # Build file dataframe from dictionary\n",
    "                file_df = pd.DataFrame.from_dict(fileDictionary, orient='index').transpose()\n",
    "\n",
    "                # Release memory of fileDictionary TODO: Why do we need to do this? Is it necessary?\n",
    "                fileDictionary = {}\n",
    "\n",
    "                # Insert user_id and session_id from session dataframe\n",
    "                user_id = session_df.loc[session_df['session_id'] == session_id, 'user_id'].iloc[0]\n",
    "                file_df.insert(0, 'session_id', session_id)\n",
    "                file_df.insert(1, 'user_id', user_id)\n",
    "\n",
    "                # Append to list of file dataframes\n",
    "                file_dfs.append(file_df)\n",
    "\n",
    "    # Concatenate dataframes from files into single dataframe\n",
    "    tap_df = pd.concat(file_dfs)\n",
    "\n",
    "    # Clean dataframe\n",
    "    tap_df = clean_tap_df(tap_df)\n",
    "\n",
    "    return tap_df\n",
    "\n",
    "\n",
    "def clean_tap_df(tap_df):\n",
    "    # Rename Columns\n",
    "    tap_df = tap_df.rename(columns={\n",
    "        'Time': 'mille',\n",
    "        'Tapped': 'tapped',\n",
    "        'Action': 'action',\n",
    "        'X': 'x',\n",
    "        'Y': 'y',\n",
    "        'Size': 'size',\n",
    "        'Pressure': 'pressure'\n",
    "    })\n",
    "\n",
    "    # Replace Actions\n",
    "    tap_df['action'] = tap_df['action'].replace(to_replace={\n",
    "        '0': 'DOWN-1ST',\n",
    "        '2': 'MOVE',\n",
    "        '1': 'UP-LAST'\n",
    "    })\n",
    "\n",
    "    # Generate unique Event IDs for all events starting with 'DOWN-1ST'\n",
    "    tap_df.insert(2, 'event_no', (tap_df['action'] == 'DOWN-1ST').cumsum())\n",
    "\n",
    "    # Specify Data Types\n",
    "    tap_df = tap_df.astype({\n",
    "        'mille': 'int64',\n",
    "        'tapped': 'int32',\n",
    "        'x': 'float64',\n",
    "        'y': 'float64',\n",
    "        'size': 'float64',\n",
    "        'pressure': 'float64'\n",
    "    })\n",
    "\n",
    "    return tap_df\n",
    "\n",
    "\n",
    "# return tap_df as global variable\n",
    "tap_df = get_tap_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_no</th>\n",
       "      <th>mille</th>\n",
       "      <th>tapped</th>\n",
       "      <th>action</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>size</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p7_38</td>\n",
       "      <td>14T1227</td>\n",
       "      <td>1</td>\n",
       "      <td>2508201</td>\n",
       "      <td>1</td>\n",
       "      <td>DOWN-1ST</td>\n",
       "      <td>186.7356</td>\n",
       "      <td>87.57617</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>1.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p7_38</td>\n",
       "      <td>14T1227</td>\n",
       "      <td>1</td>\n",
       "      <td>2508228</td>\n",
       "      <td>1</td>\n",
       "      <td>MOVE</td>\n",
       "      <td>186.7356</td>\n",
       "      <td>87.57617</td>\n",
       "      <td>0.223633</td>\n",
       "      <td>1.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p7_38</td>\n",
       "      <td>14T1227</td>\n",
       "      <td>1</td>\n",
       "      <td>2508245</td>\n",
       "      <td>1</td>\n",
       "      <td>MOVE</td>\n",
       "      <td>186.7356</td>\n",
       "      <td>87.57617</td>\n",
       "      <td>0.223633</td>\n",
       "      <td>1.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p7_38</td>\n",
       "      <td>14T1227</td>\n",
       "      <td>1</td>\n",
       "      <td>2508262</td>\n",
       "      <td>1</td>\n",
       "      <td>MOVE</td>\n",
       "      <td>186.7356</td>\n",
       "      <td>87.57617</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p7_38</td>\n",
       "      <td>14T1227</td>\n",
       "      <td>1</td>\n",
       "      <td>2508278</td>\n",
       "      <td>1</td>\n",
       "      <td>UP-LAST</td>\n",
       "      <td>186.7356</td>\n",
       "      <td>87.57617</td>\n",
       "      <td>0.224609</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  session_id  user_id  event_no    mille  tapped    action         x  \\\n",
       "0      p7_38  14T1227         1  2508201       1  DOWN-1ST  186.7356   \n",
       "1      p7_38  14T1227         1  2508228       1      MOVE  186.7356   \n",
       "2      p7_38  14T1227         1  2508245       1      MOVE  186.7356   \n",
       "3      p7_38  14T1227         1  2508262       1      MOVE  186.7356   \n",
       "4      p7_38  14T1227         1  2508278       1   UP-LAST  186.7356   \n",
       "\n",
       "          y      size  pressure  \n",
       "0  87.57617  0.224609    1.0500  \n",
       "1  87.57617  0.223633    1.0625  \n",
       "2  87.57617  0.223633    1.0500  \n",
       "3  87.57617  0.224609    1.0000  \n",
       "4  87.57617  0.224609    1.0000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tap_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
