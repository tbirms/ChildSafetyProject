{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Age Group Classification using Multiple Touchscreen Gestures**\n",
    "\n",
    "### Child Safety Project\n",
    "\n",
    "Tom Birmingham & Dr. Hossain, Southern CT State University, Computer Science Department, New Haven, CT\n",
    "\n",
    "![University Banner](<https://clubrunner.blob.core.windows.net/00000400324/EventImages/951e9035-3850-4f27-99d4-5a5d4bd17430-southern-connecticut-state-university(1).jpg>)\n",
    "\n",
    "photo: [connecticut.csteachers.org](https://connecticut.csteachers.org/events/chapter-meeting-november-2019-southern-connecticut-state-university)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook represents the thesis work of graduate student Thomas Birmingham under the advisement of Dr. Hossain, Southern Connecticut State University (SCSU) Computer Science Department.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The purpose of the project is to further the state-of-the-art in age group classification using multiple touchscreen gestures and parallel fusion. Previous methods for classifying users (as child, teen, or adult) have been performed by other students in the project with Tap, Zoom, and Swipe gestures using machine learning. In order to further the state-of-the-art, this project will combine gestures using three types of parallel fusion to determine the most effective method for age group classification using multiple touchscreen gestures.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "In order to determine the most effective method of parallel fusion for age classification, we must first obtain the same or better results of classification using features of each gesture Swipe, Zoom, and Tap. After classificiton of each gesture is completed, classification with parallel fusion will be performed at the feature level, score level, and decision level. The performance of each level of fusion will be assessed to determine the most effective method for age group classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created on Apple M3 Max with 36 GB of memory. Not everyone has access to these computerers so this notebook can be made to run on Google Colab as well, where students can access shared compute resources with large amounts of RAM. This project has also been reviewed for memory optimization to reduce the amount of memory required to run these notebooks. For example, after loading the Child Safety Dataset, a Python object for each gesture is created as a Pandas Dataframes and exported to the /Checkpoints directory as a Python \"pickle\" file. Working from /Checkpoints allows users to resume their work without the time or space complexity of working with the raw dataset. You can check how much memory is available on your current runtime by running the following code block:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check available memory\n",
    "from psutil import virtual_memory\n",
    "\n",
    "\n",
    "def print_available_memory():\n",
    "    ram_gb = virtual_memory().total / 1024**3\n",
    "    print('Your runtime has {:.1f} GB of available RAM\\n'.format(ram_gb))\n",
    "    if ram_gb < 20:\n",
    "        print('This is not considered a high-RAM runtime')\n",
    "    else:\n",
    "        print('This is considered a high-RAM runtime')\n",
    "\n",
    "\n",
    "print_available_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Any variable **not** contained within a fuction is treated as a global variable. In the above code block, notice the variable `ram_gb` is contained within the function `print_available_memory()`. Variables that are contained within a function do not persist after the function has been called. Variables outside of functions are treated as global variables, will persist, and use available memory. While you work with this notebook, try not to use variables outside of function definitions unless they are needed. You can check variables in memory and their size in bytes using the following code block:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "initial_vars = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith(\n",
    "    '_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Initialize total\n",
    "total = 0\n",
    "\n",
    "# Print header\n",
    "print(f\"{'variable':<15}{'size (bytes)':<15}\")\n",
    "print(f\"{'--------':<15}{'------------':<15}\")\n",
    "\n",
    "# Print each variable and its size\n",
    "for (var, size) in initial_vars:\n",
    "    total += size\n",
    "    if size > 160 and var not in [\"initial_vars\", \"total\"]:\n",
    "        print(f\"{var:<15}{size:<15}\")\n",
    "\n",
    "# Print total in KB or MB\n",
    "if total < 1024 * 1024:\n",
    "    print(f\"\\n{'TOTAL:':<15}{total/1024:.1f} KB\")\n",
    "elif total < 1024 * 1024 * 1024:\n",
    "    print(f\"\\n{'TOTAL:':<15}{total/1024/1024:.1f} MB\")\n",
    "else:\n",
    "    print(f\"\\n{'TOTAL:':<15}{total/1024/1024/1024:.1f} GB\")\n",
    "\n",
    "# Delete temporary variables\n",
    "del ipython_vars, initial_vars, var, size, total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell at any time to show what variables are used in memory and the total amount of memory used by these . Unused variables can be removed with the `del` keyword followed by the variable. Remove them after the cell where they are no longer used!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Helper Functions\n",
    "\n",
    "run Python Standard Library imports, Third-Party imports, and load helper functions into memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import inspect\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "\n",
    "def load_dataframe(df_name):\n",
    "    filepath = os.path.join(\"Checkpoints\", f\"{df_name}.pkl\")\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'rb') as input:\n",
    "            df = pd.read_pickle(input)\n",
    "            print(f\"Loaded {df_name} from {filepath}\")\n",
    "            return df\n",
    "    else:\n",
    "        print(f\"File {filepath} does not exist.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_dataframe(df):\n",
    "    # Create the Checkpoints directory if it doesn't exist\n",
    "    checkpoints_dir = 'Checkpoints'\n",
    "    if not os.path.exists(checkpoints_dir):\n",
    "        os.makedirs(checkpoints_dir)\n",
    "    \n",
    "    # Get the variable name of the DataFrame dynamically\n",
    "    frame = inspect.currentframe().f_back\n",
    "    variable_name = None\n",
    "    for name, value in frame.f_locals.items():\n",
    "        if value is df:\n",
    "            variable_name = name\n",
    "            break\n",
    "\n",
    "    if variable_name is None:\n",
    "        raise ValueError(\"Could not determine the variable name of the DataFrame.\")\n",
    "    \n",
    "    # Create the file path\n",
    "    file_path = os.path.join(checkpoints_dir, f\"{variable_name}.pkl\")\n",
    "\n",
    "    # Save the DataFrame as a pickle file\n",
    "    with open(file_path, 'wb') as output:\n",
    "        pickle.dump(df, output)\n",
    "        print(f\"DataFrame saved as {file_path}\")\n",
    "    \n",
    "\n",
    "def get_dataset_files():\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print(\"Using Google Colab hosted runtime\")\n",
    "        files = get_dataset_files_from_google_drive()\n",
    "    else:\n",
    "        print(\"Using local runtime\")\n",
    "        files = get_dataset_files_locally()\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_dataset_files_from_google_drive():\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "    # Create Symbolic Links to directories 'Child_Safety_Data' and 'Checkpoints'\n",
    "    ! ln -s \"/content/drive/MyDrive/Child Safety Project/Child_Safety_Data\"\n",
    "    ! ln -s \"/content/drive/MyDrive/Child Safety Project/Checkpoints\"\n",
    "\n",
    "    # Get files in Child_Safety_Data and output total number of files\n",
    "    files = glob(r'Child_Safety_Data/**/*.txt', recursive=True)\n",
    "    print(\"Total Files:\", len(files))\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_dataset_files_locally():\n",
    "    files = glob(r'../Dataset/Child_Safety_Data/**/*.txt', recursive=True)\n",
    "    print(\"Total Files:\", len(files))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "The Data Collection section loads the required data from the `Child_Safety_Data` dataset into Pandas DataFrames for further Feature Extraction, Classification, and Regression. The resulting DataFrames are:\n",
    "\n",
    "- `user_df` containing demographics data about each study participant. Only uniquely identifyable study participants are retained.\n",
    "- `session_df` containing session data for each user's session. Each session is a data collection event with multiple touchscreen gestures for one type of gesture (tap, zoom, or swipe).\n",
    "- `tap_df` containing raw data from all tap events.\n",
    "- `zoom_df` containing raw data from all zoom events (zoom-in and zoom-out).\n",
    "- `swipe_df` containing raw data from all swipe events (swipe-up, swipe-down, swipe-left, swipe-right).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Users\n",
    "\n",
    "define `get_user_df()` to build or retrieve `user_df` from Checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    user_df = load_dataframe(\"user_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (user_df is None):\n",
    "        user_df = build_user_df()\n",
    "        save_dataframe(user_df)\n",
    "\n",
    "    return user_df\n",
    "\n",
    "\n",
    "def build_user_df():\n",
    "\n",
    "    # a list of dataframes, one user for each file in the dataset, to be concatenated into a single dataframe, user_df\n",
    "    user_file_dfs = list()\n",
    "\n",
    "    for file in get_dataset_files():\n",
    "        filename = file.split('/')[-1]\n",
    "        if \"mod0\" in filename:\n",
    "            with open(file) as file:\n",
    "                # user data to extract from each file\n",
    "                user_id = ''\n",
    "                researcher = ''\n",
    "                grade = ''\n",
    "                gender = ''\n",
    "                age = ''\n",
    "                teacher = ''\n",
    "\n",
    "                # researcher\n",
    "                if filename[0] == '_':\n",
    "                    researcher = 'Carl'\n",
    "                elif filename[0] != '_':\n",
    "                    researcher = 'Kate'\n",
    "\n",
    "                # get data from file\n",
    "                for line in file:\n",
    "\n",
    "                    # collect key value pairs from file\n",
    "                    if \"=\" in line:\n",
    "                        key, value = line.strip().split(\"=\")\n",
    "\n",
    "                        key = key.lower()\n",
    "                        if key == \"grade\":\n",
    "                            grade = value\n",
    "                        elif key == \"gender\" or key == \"student\":\n",
    "                            gender = value\n",
    "                        elif key == \"age\" or key == \"studentage\":\n",
    "                            age = value\n",
    "                        elif key == \"teacher\":\n",
    "                            teacher = value\n",
    "\n",
    "                # User Unique Identifiers\n",
    "                if researcher == 'Carl':\n",
    "                    user_id = filename.split('_')[1]\n",
    "                elif researcher == 'Kate':\n",
    "                    user_id = teacher + grade + gender + age\n",
    "\n",
    "                # Note: Kate had recorded data differently than Carl\n",
    "                # where Carl collected [datetime, session number, machine name, grade,\n",
    "                # gender, age, middle initial, birth month, and birth day],\n",
    "                # Kate collected [datetime, session number, machine name, teacher,\n",
    "                # grade, gender, and age].\n",
    "                # Carl generated and assigned a unique identifier to each study participant,\n",
    "                # but we do not have a unique identifier for each of Kate's participants.\n",
    "                # We try to generate as unique an identifier as possible using a combination of\n",
    "                # teacher, grade, gender, and age, but there are duplicate user ids and\n",
    "                # therefore we cannot use all Kate's data. This is only an issue as we need\n",
    "                # to combine multiple gestures for each user, where each user's gesture samples\n",
    "                # comes from a different session.\n",
    "\n",
    "                # create user dataframe for each file and append it to a list\n",
    "                user_data = {}\n",
    "                user_data['user_id'] = user_id\n",
    "                user_data['age'] = age\n",
    "                user_data['grade'] = grade\n",
    "                user_data['gender'] = gender\n",
    "                user_data['researcher'] = researcher\n",
    "                user_file_df = pd.DataFrame(user_data, index=[0])\n",
    "                user_file_dfs.append(user_file_df)\n",
    "\n",
    "    # concatenate dataframes of user data into a single dataframe\n",
    "    user_df = pd.concat(user_file_dfs)\n",
    "\n",
    "    # remove all user ids that are duplicates from kate\n",
    "    # (cannot assign sessions from duplicate users to a unique user)\n",
    "    is_duplicate_kate = (user_df['researcher'] == 'Kate') & user_df.duplicated(\n",
    "        subset='user_id', keep=False)\n",
    "    user_df = user_df[~is_duplicate_kate | (user_df['researcher'] != 'Kate')]\n",
    "\n",
    "    # Keep first user_id from Carl\n",
    "    user_df = user_df.drop_duplicates(subset='user_id', keep='first')\n",
    "\n",
    "    # reset indexes\n",
    "    user_df = user_df.reset_index(drop=True)\n",
    "\n",
    "    # set data types\n",
    "    user_df['age'] = user_df['age'].astype(int)\n",
    "    user_df['grade'] = user_df['grade'].astype(int)\n",
    "\n",
    "    # add age group\n",
    "    user_df['age_group'] = user_df['age'].apply(get_age_group)\n",
    "\n",
    "    return user_df\n",
    "\n",
    "\n",
    "def get_age_group(age):\n",
    "    if age < 13:\n",
    "        return 'child'\n",
    "    elif age < 18:\n",
    "        return 'teen'\n",
    "    else:\n",
    "        return 'adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sessions\n",
    "\n",
    "define `get_session_df()` to build or retrieve `session_df` from Checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    session_df = load_dataframe(\"session_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (session_df is None):\n",
    "        session_df = build_session_df()\n",
    "        save_dataframe(session_df)\n",
    "\n",
    "    return session_df\n",
    "\n",
    "\n",
    "def build_session_df():\n",
    "    print(\"Building session_df from data\")\n",
    "\n",
    "    # a list of dataframes, one session for each file in the dataset, to be concatenated into a single dataframe, user_df\n",
    "    session_file_dfs = list()\n",
    "\n",
    "    for file in get_dataset_files():\n",
    "\n",
    "        filename = file.split('/')[-1]\n",
    "\n",
    "        if \"mod0\" in filename:\n",
    "\n",
    "            with open(file) as file:\n",
    "\n",
    "                # expected data in file\n",
    "                session_id = ''\n",
    "                user_id = ''\n",
    "                researcher = ''\n",
    "                datetime = ''\n",
    "                device = ''\n",
    "                device_type = ''\n",
    "                session = ''\n",
    "                grade = ''\n",
    "                gender = ''\n",
    "                age = ''\n",
    "                teacher = ''\n",
    "\n",
    "                # researcher\n",
    "                if filename[0] == '_':\n",
    "                    researcher = 'Carl'\n",
    "                elif filename[0] != '_':\n",
    "                    researcher = 'Kate'\n",
    "\n",
    "                # get data from file\n",
    "                for line in file:\n",
    "                    if \"=\" in line:\n",
    "\n",
    "                        # collect key value pairs from file\n",
    "                        key, value = line.strip().split(\"=\")\n",
    "                        key = key.lower()\n",
    "                        if key == \"colldatetime\":\n",
    "                            datetime = value\n",
    "                        elif key == \"machname\":\n",
    "                            device = value\n",
    "                        elif key == \"session\":\n",
    "                            session = value\n",
    "                        elif key == \"grade\":\n",
    "                            grade = value\n",
    "                        elif key == \"gender\" or key == \"student\":\n",
    "                            gender = value\n",
    "                        elif key == \"age\" or key == \"studentage\":\n",
    "                            age = value\n",
    "                        elif key == \"teacher\":\n",
    "                            teacher = value\n",
    "\n",
    "                session_id = device + \"_\" + session\n",
    "\n",
    "                # User Unique Identifiers\n",
    "                if researcher == 'Carl':\n",
    "                    user_id = filename.split('_')[1]\n",
    "                elif researcher == 'Kate':\n",
    "                    user_id = teacher + grade + gender + age\n",
    "\n",
    "                # Device Type\n",
    "                if 'm' in device:\n",
    "                    device_type = 'tablet'\n",
    "                elif 'p' in device:\n",
    "                    device_type = 'phone'\n",
    "\n",
    "                # create session dataframe for each file and append it to a list\n",
    "                session_data = {}\n",
    "                session_data['session_id'] = session_id\n",
    "                session_data['user_id'] = user_id\n",
    "                session_data['datatime'] = datetime\n",
    "                session_data['device'] = device\n",
    "                session_data['session'] = session\n",
    "                session_data['device_type'] = device_type\n",
    "                session_file_df = pd.DataFrame(session_data, index=[0])\n",
    "                session_file_dfs.append(session_file_df)\n",
    "\n",
    "    # Create Session DataFrame\n",
    "    session_df = pd.concat(session_file_dfs)\n",
    "\n",
    "    # Drop sessions from session dataframe where there is not a unique user id\n",
    "    print(\"Removing sessions where there is not a unique user id...\")\n",
    "    unique_user_ids = get_user_df()['user_id'].unique()\n",
    "    mask = session_df['user_id'].isin(unique_user_ids)\n",
    "    session_df = session_df[mask]\n",
    "\n",
    "    # reset index\n",
    "    session_df = session_df.reset_index(drop=True)\n",
    "\n",
    "    return session_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_session_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Tap Data\n",
    "\n",
    "define `get_tap_df()` to build or retrieve `tap_df` from Checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tap_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    tap_df = load_dataframe(\"tap_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (tap_df is None):\n",
    "        tap_df = build_tap_df()\n",
    "        save_dataframe(tap_df)\n",
    "\n",
    "    return tap_df\n",
    "\n",
    "\n",
    "def build_tap_df():\n",
    "    print(\"Building tap_df...\")\n",
    "\n",
    "    # Initialize Data Structures\n",
    "    file_df = pd.DataFrame()\n",
    "    file_dfs = list()\n",
    "    tap_df = pd.DataFrame()\n",
    "    user_df = get_user_df()\n",
    "    session_df = get_session_df()\n",
    "\n",
    "    for file in get_dataset_files():\n",
    "\n",
    "        # get filename\n",
    "        filename = file.split('/')[-1]\n",
    "\n",
    "        # get session id\n",
    "        session_id = filename.split('_')[-4] + '_' + filename.split('_')[-3]\n",
    "\n",
    "        # Process mod5 (tap) files only if a session was captured\n",
    "        if ('mod5' in filename) and (session_id in session_df['session_id'].unique()):\n",
    "\n",
    "            with open(file) as file:\n",
    "\n",
    "                fileDictionary = {}\n",
    "\n",
    "                for line in file:\n",
    "                    line = line.strip()\n",
    "\n",
    "                    if line:\n",
    "                        # Add key and value list to dictionary\n",
    "                        if \":\" in line:\n",
    "                            # split the line into key and values\n",
    "                            key, values = line.split(': ')\n",
    "                            # split values into list\n",
    "                            values = values.split(' ')\n",
    "                            # add the key-value pair to the dictionary\n",
    "                            fileDictionary[key] = values\n",
    "\n",
    "                # Build file dataframe from dictionary\n",
    "                file_df = pd.DataFrame.from_dict(\n",
    "                    fileDictionary, orient='index').transpose()\n",
    "\n",
    "                # get user id\n",
    "                user_id = session_df.loc[session_df['session_id']\n",
    "                                         == session_id, 'user_id'].iloc[0]\n",
    "\n",
    "                # get age\n",
    "                age = user_df.loc[user_df['user_id'] == user_id, 'age'].iloc[0]\n",
    "\n",
    "                # get age group\n",
    "                age_group = user_df.loc[user_df['user_id']\n",
    "                                        == user_id, 'age_group'].iloc[0]\n",
    "\n",
    "                # get device type\n",
    "                device_type = session_df.loc[session_df['session_id']\n",
    "                                             == session_id, 'device_type'].iloc[0]\n",
    "\n",
    "                # Insert gesture, user_id, and session_id\n",
    "                file_df.insert(0, 'user_id', user_id)\n",
    "                file_df.insert(1, 'device_type', device_type)\n",
    "                file_df.insert(2, 'session_id', session_id)\n",
    "                file_df.insert(3, 'age', age)\n",
    "                file_df.insert(4, 'age_group', age_group)\n",
    "\n",
    "                # Append to list of file dataframes\n",
    "                file_dfs.append(file_df)\n",
    "\n",
    "    # Concatenate dataframes from files into single dataframe\n",
    "    tap_df = pd.concat(file_dfs)\n",
    "\n",
    "    # Insert gesture column\n",
    "    tap_df.insert(0, 'gesture', 'tap')\n",
    "\n",
    "    # Clean dataframe\n",
    "    tap_df = clean_tap_df(tap_df)\n",
    "\n",
    "    return tap_df\n",
    "\n",
    "\n",
    "def clean_tap_df(tap_df):\n",
    "    # Rename Columns\n",
    "    tap_df = tap_df.rename(columns={\n",
    "        'Time': 'mille',\n",
    "        'Tapped': 'tapped',\n",
    "        'Action': 'action',\n",
    "        'X': 'x',\n",
    "        'Y': 'y',\n",
    "        'Size': 'size',\n",
    "        'Pressure': 'pressure'\n",
    "    })\n",
    "\n",
    "    # Replace Actions\n",
    "    tap_df['action'] = tap_df['action'].replace(to_replace={\n",
    "        '0': 'DOWN-1ST',\n",
    "        '2': 'MOVE',\n",
    "        '1': 'UP-LAST'\n",
    "    })\n",
    "\n",
    "    # Generate unique Event IDs for all events starting with 'DOWN-1ST'\n",
    "    tap_df.insert(1, 'event_no', (tap_df['action'] == 'DOWN-1ST').cumsum())\n",
    "\n",
    "    # Specify Data Types\n",
    "    tap_df = tap_df.astype({\n",
    "        'mille': 'int64',\n",
    "        'tapped': 'int32',\n",
    "        'x': 'float64',\n",
    "        'y': 'float64',\n",
    "        'size': 'float64',\n",
    "        'pressure': 'float64'\n",
    "    })\n",
    "\n",
    "    return tap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tap_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Zoom Data\n",
    "\n",
    "define `get_zoom_df()` to build or retrieve `zoom_df` from Checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zoom_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    zoom_df = load_dataframe(\"zoom_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (zoom_df is None):\n",
    "        zoom_df = build_zoom_df()\n",
    "        save_dataframe(zoom_df)\n",
    "\n",
    "    return zoom_df\n",
    "\n",
    "\n",
    "def build_zoom_df():\n",
    "    print(\"Building zoom_df...\")\n",
    "\n",
    "    # Initialize Data Structures\n",
    "    file_df = pd.DataFrame()\n",
    "    file_dfs = list()\n",
    "    zoom_df = pd.DataFrame()\n",
    "    user_df = get_user_df()\n",
    "    session_df = get_session_df()\n",
    "\n",
    "    # Select Event Source:\n",
    "    #   'tc' for current event or\n",
    "    #   'th' for history queue\n",
    "    # both sources of data are available in the dataset\n",
    "    source = 'tc'\n",
    "\n",
    "    for file in get_dataset_files():\n",
    "\n",
    "        # get filename\n",
    "        filename = file.split('/')[-1]\n",
    "\n",
    "        # get session id\n",
    "        session_id = filename.split('_')[-4] + '_' + filename.split('_')[-3]\n",
    "\n",
    "       # Process Zoom Gestures (mod6) if session in session dataframe\n",
    "        if ('mod6' in filename) and (session_id in session_df['session_id'].unique()):\n",
    "\n",
    "            # open file and read all json lines into event list\n",
    "            event_list = []\n",
    "            with open(file) as file:\n",
    "\n",
    "                # select lines from selected source\n",
    "                for line in file:\n",
    "                    line = json.loads(line)\n",
    "                    if \"type\" in line and line[\"type\"] == source.lower():\n",
    "\n",
    "                        line[\"mille\"] = line[\"mille\"]\n",
    "                        line[\"pcnt\"] = line[\"pcnt\"]\n",
    "                        line[\"pid\"] = line[\"pid\"]\n",
    "                        line[\"pidx\"] = line[\"pidx\"]\n",
    "                        line[\"x\"] = line[\"x\"]\n",
    "                        line[\"y\"] = line[\"y\"]\n",
    "                        line[\"size\"] = line[\"size\"]\n",
    "                        line[\"press\"] = line[\"press\"]\n",
    "                        line[\"vx\"] = line[\"vx\"]\n",
    "                        line[\"vy\"] = line[\"vy\"]\n",
    "\n",
    "                        # Append json to event list\n",
    "                        event_list.append(line)\n",
    "\n",
    "            # Build file dataframe from event list\n",
    "            file_df = pd.DataFrame(event_list)\n",
    "\n",
    "            # Drop unused columns from DataFrame\n",
    "            if 'src' in file_df:\n",
    "                file_df = file_df.drop(columns=['src'])\n",
    "\n",
    "            # get user id\n",
    "            user_id = session_df.loc[session_df['session_id']\n",
    "                                     == session_id, 'user_id'].iloc[0]\n",
    "\n",
    "            # get age\n",
    "            age = user_df.loc[user_df['user_id'] == user_id, 'age'].iloc[0]\n",
    "\n",
    "            # get age group\n",
    "            age_group = user_df.loc[user_df['user_id']\n",
    "                                    == user_id, 'age_group'].iloc[0]\n",
    "\n",
    "            # get device type\n",
    "            device_type = session_df.loc[session_df['session_id']\n",
    "                                         == session_id, 'device_type'].iloc[0]\n",
    "\n",
    "            # Insert gesture, user_id, and session_id\n",
    "            file_df.insert(0, 'user_id', user_id)\n",
    "            file_df.insert(1, 'device_type', device_type)\n",
    "            file_df.insert(2, 'session_id', session_id)\n",
    "            file_df.insert(3, 'age', age)\n",
    "            file_df.insert(4, 'age_group', age_group)\n",
    "\n",
    "            # Append to list of all file dataframes\n",
    "            file_dfs.append(file_df)\n",
    "\n",
    "    # Concatenate all file dataframes into single dataframe\n",
    "    zoom_df = pd.concat(file_dfs)\n",
    "\n",
    "    # Rename columns\n",
    "    zoom_df = zoom_df.rename(columns={\n",
    "        \"act\": \"action\",\n",
    "        \"press\": \"pressure\"\n",
    "    })\n",
    "\n",
    "    # Insert gesture column\n",
    "    zoom_df.insert(0, 'gesture', 'zoom')\n",
    "\n",
    "    # Insert uniquely generated Event IDs for all events starting with 'DOWN-1ST'\n",
    "    zoom_df.insert(1, 'event_no', (zoom_df['action'] == 'DOWN-1ST').cumsum())\n",
    "\n",
    "    # Set data types\n",
    "    zoom_df['mille'] = zoom_df['mille'].astype(int)\n",
    "    zoom_df['pcnt'] = zoom_df['pcnt'].astype(int)\n",
    "    zoom_df['pid'] = zoom_df['pid'].astype(int)\n",
    "    zoom_df['pidx'] = zoom_df['pidx'].astype(int)\n",
    "    zoom_df['x'] = zoom_df['x'].astype(float)\n",
    "    zoom_df['y'] = zoom_df['y'].astype(float)\n",
    "    zoom_df['size'] = zoom_df['size'].astype(float)\n",
    "    zoom_df['pressure'] = zoom_df['pressure'].astype(float)\n",
    "    zoom_df['vx'] = zoom_df['vx'].astype(float)\n",
    "    zoom_df['vy'] = zoom_df['vy'].astype(float)\n",
    "\n",
    "    # Set all velocities to positive\n",
    "    zoom_df['vx'] = zoom_df['vx'].abs()\n",
    "    zoom_df['vy'] = zoom_df['vy'].abs()\n",
    "\n",
    "    # Replace null (NaN) values in 'vx' and 'vy' with 0\n",
    "    zoom_df['vx'] = zoom_df['vx'].fillna(0)\n",
    "    zoom_df['vy'] = zoom_df['vy'].fillna(0)\n",
    "\n",
    "    # Replace infinite values in 'vx' or 'vy' with 0\n",
    "    zoom_df['vx'] = zoom_df['vx'].replace([np.inf, -np.inf], 0)\n",
    "    zoom_df['vy'] = zoom_df['vy'].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    return zoom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_zoom_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Swipe Data\n",
    "\n",
    "define `get_swipe_df()` to build `swipe_df` from data or retrieve it from Checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swipe_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    swipe_df = load_dataframe(\"swipe_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (swipe_df is None):\n",
    "        swipe_df = build_swipe_df()\n",
    "        save_dataframe(swipe_df)\n",
    "\n",
    "    return swipe_df\n",
    "\n",
    "\n",
    "def build_swipe_df():\n",
    "    print(\"Building swipe_df...\")\n",
    "\n",
    "    # Initialize Data Structures\n",
    "    file_df = pd.DataFrame()\n",
    "    file_dfs = list()\n",
    "    swipe_df = pd.DataFrame()\n",
    "    user_df = get_user_df()\n",
    "    session_df = get_session_df()\n",
    "\n",
    "    # Select Event Source:\n",
    "    #   'tc' for current event or\n",
    "    #   'th' for history queue\n",
    "    # both sources of data are available in the dataset\n",
    "    source = 'tc'\n",
    "\n",
    "    for file in get_dataset_files():\n",
    "\n",
    "        # get filename\n",
    "        filename = file.split('/')[-1]\n",
    "\n",
    "        # get session id\n",
    "        session_id = filename.split('_')[-4] + '_' + filename.split('_')[-3]\n",
    "\n",
    "        # Process Swipe Gestures (mod2, mod3) if session in session dataframe\n",
    "        if ('mod2' in filename or 'mod3' in filename) and \\\n",
    "                session_id in session_df['session_id'].unique():\n",
    "\n",
    "            # open file and read all json lines into event list\n",
    "            event_list = []\n",
    "            with open(file) as file:\n",
    "\n",
    "                # select lines from selected source\n",
    "                for line in file:\n",
    "                    line = json.loads(line)\n",
    "                    if \"type\" in line and line[\"type\"] == source.lower():\n",
    "\n",
    "                        line[\"mille\"] = line[\"mille\"]\n",
    "                        line[\"pcnt\"] = line[\"pcnt\"]\n",
    "                        line[\"pid\"] = line[\"pid\"]\n",
    "                        line[\"pidx\"] = line[\"pidx\"]\n",
    "                        line[\"x\"] = line[\"x\"]\n",
    "                        line[\"y\"] = line[\"y\"]\n",
    "                        line[\"size\"] = line[\"size\"]\n",
    "                        line[\"press\"] = line[\"press\"]\n",
    "                        line[\"vx\"] = line[\"vx\"]\n",
    "                        line[\"vy\"] = line[\"vy\"]\n",
    "\n",
    "                        # Horizontal and Vertical Labels\n",
    "                        if 'mod2' in line['test']:\n",
    "                            line['test'] = 'horizontal'\n",
    "                        elif 'mod3' in line['test']:\n",
    "                            line['test'] = 'vertical'\n",
    "\n",
    "                        # Append json to event list\n",
    "                        event_list.append(line)\n",
    "\n",
    "            # Build file dataframe from event list\n",
    "            file_df = pd.DataFrame(event_list)\n",
    "\n",
    "            # Drop unused columns from DataFrame\n",
    "            if 'src' in file_df:\n",
    "                file_df = file_df.drop(columns=['src'])\n",
    "\n",
    "            # get user id\n",
    "            user_id = session_df.loc[session_df['session_id']\n",
    "                                     == session_id, 'user_id'].iloc[0]\n",
    "\n",
    "            # get age\n",
    "            age = user_df.loc[user_df['user_id'] == user_id, 'age'].iloc[0]\n",
    "\n",
    "            # get age group\n",
    "            age_group = user_df.loc[user_df['user_id']\n",
    "                                    == user_id, 'age_group'].iloc[0]\n",
    "\n",
    "            # get device type\n",
    "            device_type = session_df.loc[session_df['session_id']\n",
    "                                         == session_id, 'device_type'].iloc[0]\n",
    "\n",
    "            # Insert user_id and session_id from session dataframe\n",
    "            file_df.insert(0, 'user_id', user_id)\n",
    "            file_df.insert(1, 'device_type', device_type)\n",
    "            file_df.insert(2, 'session_id', session_id)\n",
    "            file_df.insert(3, 'age', age)\n",
    "            file_df.insert(4, 'age_group', age_group)\n",
    "\n",
    "            # Append to list of all file dataframes\n",
    "            file_dfs.append(file_df)\n",
    "\n",
    "    # Concatenate all file dataframes into single swipe dataframe\n",
    "    swipe_df = pd.concat(file_dfs)\n",
    "\n",
    "    # Rename columns\n",
    "    swipe_df = swipe_df.rename(columns={\n",
    "        \"test\": \"orientation\",\n",
    "        \"act\": \"action\",\n",
    "        \"press\": \"pressure\"\n",
    "    })\n",
    "\n",
    "    # Insert gesture column\n",
    "    swipe_df.insert(0, 'gesture', 'swipe')\n",
    "\n",
    "    # Generate unique Event IDs for all events starting with 'DOWN-1ST'\n",
    "    swipe_df.insert(1, 'event_no', (swipe_df['action'] == 'DOWN-1ST').cumsum())\n",
    "\n",
    "    # Set data types\n",
    "    swipe_df['mille'] = swipe_df['mille'].astype(int)\n",
    "    swipe_df['pcnt'] = swipe_df['pcnt'].astype(int)\n",
    "    swipe_df['pid'] = swipe_df['pid'].astype(int)\n",
    "    swipe_df['pidx'] = swipe_df['pidx'].astype(int)\n",
    "    swipe_df['x'] = swipe_df['x'].astype(float)\n",
    "    swipe_df['y'] = swipe_df['y'].astype(float)\n",
    "    swipe_df['size'] = swipe_df['size'].astype(float)\n",
    "    swipe_df['pressure'] = swipe_df['pressure'].astype(float)\n",
    "    swipe_df['vx'] = swipe_df['vx'].astype(float)\n",
    "    swipe_df['vy'] = swipe_df['vy'].astype(float)\n",
    "\n",
    "    # Set all velocities to positive\n",
    "    swipe_df['vx'] = swipe_df['vx'].abs()\n",
    "    swipe_df['vy'] = swipe_df['vy'].abs()\n",
    "\n",
    "    # Replace null (NaN) values in 'vx' and 'vy' with 0\n",
    "    swipe_df['vx'] = swipe_df['vx'].fillna(0)\n",
    "    swipe_df['vy'] = swipe_df['vy'].fillna(0)\n",
    "\n",
    "    # Replace infinite values in 'vx' or 'vy' with 0\n",
    "    swipe_df['vx'] = swipe_df['vx'].replace([np.inf, -np.inf], 0)\n",
    "    swipe_df['vy'] = swipe_df['vy'].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    return swipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_swipe_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "The Feature Extraction section defines and extracts features for all Tap, Zoom, and Swipe events and creates a DataFrame of features for each event of that type. The resulting DataFrames are:\n",
    "\n",
    "- `tap_features_df` containing a set of features for each tap gesture by event_no.\n",
    "- `swipe_features_df` containing a set of features for each swipe gesture by event_no.\n",
    "- `zoom_features_df` containing a set of features for each zoom gesture by event_no.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Tap Features\n",
    "\n",
    "define featuress in `TapEvent`\n",
    "define `get_tap_features_df()` to build `tap_features_df` from data or retrieve it from Checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TapEvent:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index()\n",
    "\n",
    "    def is_valid(self):\n",
    "        if self.df['action'].iloc[0] == 'DOWN-1ST' and self.df['action'].iloc[-1] == 'UP-LAST':\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def get_feature_dataframe(self):\n",
    "        # filter invalid events\n",
    "        if not self.is_valid():\n",
    "            print('Event No {} is invalid.'.format(\n",
    "                self.df['event_no'].iloc[0]))\n",
    "            return None\n",
    "\n",
    "        # return dataframe constructed from dictionary of feature key-value pairs\n",
    "        return pd.DataFrame(self.get_all_feature_values(), index=[0])\n",
    "\n",
    "    def get_all_feature_values(self):\n",
    "        feature_values = {}\n",
    "\n",
    "        # Parent DataFrame\n",
    "        feature_values['gesture'] = 'tap'\n",
    "        feature_values['tapped'] = TapEvent.get_tapped(self.df)\n",
    "        feature_values['event_no'] = TapEvent.get_event_no(self.df)\n",
    "        feature_values['session_id'] = TapEvent.get_session_id(self.df)\n",
    "        feature_values['user_id'] = TapEvent.get_user_id(self.df)\n",
    "        feature_values['device_type'] = TapEvent.get_device_type(self.df)\n",
    "        feature_values['age'] = TapEvent.get_age(self.df)\n",
    "        feature_values['age_group'] = TapEvent.get_age_group(self.df)\n",
    "\n",
    "        # Size Features\n",
    "        feature_values['start_size'] = TapEvent.get_start_size(self.df)\n",
    "        feature_values['end_size'] = TapEvent.get_end_size(self.df)\n",
    "        feature_values['max_size'] = TapEvent.get_max_size(self.df)\n",
    "        feature_values['min_size'] = TapEvent.get_min_size(self.df)\n",
    "        feature_values['avg_size'] = TapEvent.get_avg_size(self.df)\n",
    "        feature_values['range_in_size'] = TapEvent.get_range_in_size(self.df)\n",
    "\n",
    "        # Pressure Features\n",
    "        feature_values['start_pressure'] = TapEvent.get_start_pressure(self.df)\n",
    "        feature_values['end_pressure'] = TapEvent.get_end_pressure(self.df)\n",
    "        feature_values['max_pressure'] = TapEvent.get_max_pressure(self.df)\n",
    "        feature_values['min_pressure'] = TapEvent.get_min_pressure(self.df)\n",
    "        feature_values['avg_pressure'] = TapEvent.get_avg_pressure(self.df)\n",
    "        feature_values['range_in_pressure'] = TapEvent.get_range_in_pressure(\n",
    "            self.df)\n",
    "\n",
    "        # Distance Features\n",
    "        feature_values['total_distance'] = TapEvent.get_total_distance(self.df)\n",
    "        feature_values['distance_to_max_pressure'] = TapEvent.get_distance_start_max_pressure(\n",
    "            self.df)\n",
    "        feature_values['distance_to_min_pressure'] = TapEvent.get_distance_start_min_pressure(\n",
    "            self.df)\n",
    "\n",
    "        # Time Features\n",
    "        feature_values['hold_time'] = TapEvent.get_hold_time(self.df)\n",
    "        feature_values['time_to_max_pressure'] = TapEvent.get_time_to_max_pressure(\n",
    "            self.df)\n",
    "        feature_values['time_to_min_pressure'] = TapEvent.get_time_to_min_pressure(\n",
    "            self.df)\n",
    "\n",
    "        # Product Features\n",
    "        feature_values['product_of_max_size_and_max_pressure'] = TapEvent.get_product_max_size_max_pressure(\n",
    "            self.df)\n",
    "        feature_values['product_of_max_size_and_hold_time'] = TapEvent.get_product_max_size_hold_time(\n",
    "            self.df)\n",
    "        feature_values['product_of_min_size_and_hold_time'] = TapEvent.get_product_min_size_hold_time(\n",
    "            self.df)\n",
    "        feature_values['product_of_avg_size_and_hold_time'] = TapEvent.get_product_avg_size_hold_time(\n",
    "            self.df)\n",
    "\n",
    "        # Slope Features\n",
    "        feature_values['slope_start_to_end'] = TapEvent.get_slope_start_end(\n",
    "            self.df)\n",
    "        feature_values['slope_start_to_median'] = TapEvent.get_slope_start_median(\n",
    "            self.df)\n",
    "        feature_values['slope_median_to_end'] = TapEvent.get_slope_median_end(\n",
    "            self.df)\n",
    "\n",
    "        return feature_values\n",
    "\n",
    "    # Helper Methods -------------------------------------------------------------\n",
    "\n",
    "    # Data from parent DataFrame\n",
    "\n",
    "    def get_event_no(df):\n",
    "        return df['event_no'].iloc[0]\n",
    "\n",
    "    def get_user_id(df):\n",
    "        return df['user_id'].iloc[0]\n",
    "\n",
    "    def get_device_type(df):\n",
    "        return df['device_type'].iloc[0]\n",
    "\n",
    "    def get_session_id(df):\n",
    "        return df['session_id'].iloc[0]\n",
    "\n",
    "    def get_age(df):\n",
    "        return df['age'].iloc[0]\n",
    "\n",
    "    def get_age_group(df):\n",
    "        return df['age_group'].iloc[0]\n",
    "\n",
    "    def get_tapped(df):\n",
    "        return df['tapped'].iloc[0]\n",
    "\n",
    "    # Time Features\n",
    "\n",
    "    def get_time_to_max_pressure(df):\n",
    "        max_pressure_index = df['pressure'].idxmax()\n",
    "        time_to_max_pressure = df['mille'].iloc[max_pressure_index] - \\\n",
    "            df['mille'].iloc[0]\n",
    "        return time_to_max_pressure\n",
    "\n",
    "    def get_time_to_min_pressure(df):\n",
    "        min_pressure_index = df['pressure'].idxmin()\n",
    "        time_to_min_pressure = df['mille'].iloc[min_pressure_index] - \\\n",
    "            df['mille'].iloc[0]\n",
    "        return time_to_min_pressure\n",
    "\n",
    "    def get_hold_time(df):\n",
    "        hold_time = df['mille'].iloc[-1] - df['mille'].iloc[0]\n",
    "        return hold_time\n",
    "\n",
    "    # Size Features\n",
    "\n",
    "    def get_start_size(df):\n",
    "        return df['size'].iloc[0]\n",
    "\n",
    "    def get_end_size(df):\n",
    "        return df['size'].iloc[-1]\n",
    "\n",
    "    def get_max_size(df):\n",
    "        return df['size'].max()\n",
    "\n",
    "    def get_min_size(df):\n",
    "        return df['size'].min()\n",
    "\n",
    "    def get_avg_size(df):\n",
    "        return df['size'].mean()\n",
    "\n",
    "    def get_range_in_size(df):\n",
    "        return abs(TapEvent.get_max_size(df) - TapEvent.get_min_size(df))\n",
    "\n",
    "    # Pressure Features\n",
    "\n",
    "    def get_start_pressure(df):\n",
    "        return df['pressure'].iloc[0]\n",
    "\n",
    "    def get_end_pressure(df):\n",
    "        return df['pressure'].iloc[-1]\n",
    "\n",
    "    def get_max_pressure(df):\n",
    "        return df['pressure'].max()\n",
    "\n",
    "    def get_min_pressure(df):\n",
    "        return df['pressure'].min()\n",
    "\n",
    "    def get_avg_pressure(df):\n",
    "        return df['pressure'].mean()\n",
    "\n",
    "    def get_range_in_pressure(df):\n",
    "        return abs(TapEvent.get_max_pressure(df) - TapEvent.get_min_pressure(df))\n",
    "\n",
    "    # Velocity Features\n",
    "\n",
    "    def get_start_vx(df):\n",
    "        return df['vx'].iloc[0]\n",
    "\n",
    "    def get_end_vx(df):\n",
    "        return df['vx'].iloc[-1]\n",
    "\n",
    "    def get_max_vx(df):\n",
    "        return df['vx'].max()\n",
    "\n",
    "    def get_min_vx(df):\n",
    "        return df['vx'].min()\n",
    "\n",
    "    def get_avg_vx(df):\n",
    "        return df['vx'].mean()\n",
    "\n",
    "    def get_start_vy(df):\n",
    "        return df['vy'].iloc[0]\n",
    "\n",
    "    def get_end_vy(df):\n",
    "        return df['vy'].iloc[-1]\n",
    "\n",
    "    def get_max_vy(df):\n",
    "        return df['vy'].max()\n",
    "\n",
    "    def get_min_vy(df):\n",
    "        return df['vy'].min()\n",
    "\n",
    "    def get_avg_vy(df):\n",
    "        return df['vy'].mean()\n",
    "\n",
    "    def get_range_in_vy(df):\n",
    "        max_vy = TapEvent.get_max_vy(df)\n",
    "        min_vy = TapEvent.get_min_vy(df)\n",
    "        if max_vy == float('Inf') or min_vy == float('Inf'):\n",
    "            return float('Inf')\n",
    "        elif max_vy == float('NaN') or min_vy == float('NaN'):\n",
    "            return float('NaN')\n",
    "        else:\n",
    "            return abs(max_vy - min_vy)\n",
    "\n",
    "    # Distance Features\n",
    "\n",
    "    def get_total_distance(df):\n",
    "        x1, y1 = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        x2, y2 = df['x'].iloc[-1], df['y'].iloc[-1]\n",
    "        distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        return distance\n",
    "\n",
    "    def get_distance_start_max_pressure(df):\n",
    "        start_x, start_y = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        max_pressure_index = df['pressure'].idxmax()\n",
    "        max_pressure_x = df['x'].iloc[max_pressure_index]\n",
    "        max_pressure_y = df['y'].iloc[max_pressure_index]\n",
    "        distance = math.sqrt((max_pressure_x - start_x) **\n",
    "                             2 + (max_pressure_y - start_y)**2)\n",
    "        return distance\n",
    "\n",
    "    def get_distance_start_min_pressure(df):\n",
    "        start_x, start_y = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        min_pressure_index = df['pressure'].idxmin()\n",
    "        min_pressure_x = df['x'].iloc[min_pressure_index]\n",
    "        min_pressure_y = df['y'].iloc[min_pressure_index]\n",
    "        distance = math.sqrt((min_pressure_x - start_x) **\n",
    "                             2 + (min_pressure_y - start_y)**2)\n",
    "        return distance\n",
    "\n",
    "    # Product Features\n",
    "\n",
    "    def get_product_max_size_max_pressure(df):\n",
    "        return TapEvent.get_max_size(df) * TapEvent.get_max_pressure(df)\n",
    "\n",
    "    def get_product_avg_size_hold_time(df):\n",
    "        return TapEvent.get_avg_size(df) * TapEvent.get_hold_time(df)\n",
    "\n",
    "    def get_product_max_size_hold_time(df):\n",
    "        return TapEvent.get_max_size(df) * TapEvent.get_hold_time(df)\n",
    "\n",
    "    def get_product_min_size_hold_time(df):\n",
    "        return TapEvent.get_min_size(df) * TapEvent.get_hold_time(df)\n",
    "\n",
    "    # Slope Features\n",
    "\n",
    "    def get_slope_start_end(df):\n",
    "        x1, y1 = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        x2, y2 = df['x'].iloc[-1], df['y'].iloc[-1]\n",
    "        if x2 - x1 != 0:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "        else:\n",
    "            slope = float('NaN')  # vertical slope is undefined\n",
    "        return slope\n",
    "\n",
    "    def get_slope_start_median(df):\n",
    "        x1, y1 = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        median_index = len(df) // 2\n",
    "        x_median = df['x'].iloc[median_index]\n",
    "        y_median = df['y'].iloc[median_index]\n",
    "        if x_median - x1 != 0:\n",
    "            slope = (y_median - y1) / (x_median - x1)\n",
    "        else:\n",
    "            slope = float('NaN')  # vertical slope is undefined\n",
    "        return slope\n",
    "\n",
    "    def get_slope_median_end(df):\n",
    "        median_index = len(df) // 2\n",
    "        x_median = df['x'].iloc[median_index]\n",
    "        y_median = df['y'].iloc[median_index]\n",
    "        x_end = df['x'].iloc[-1]\n",
    "        y_end = df['y'].iloc[-1]\n",
    "        if x_end - x_median != 0:\n",
    "            slope = (y_end - y_median) / (x_end - x_median)\n",
    "        else:\n",
    "            slope = float('NaN')  # vertical slope is undefined\n",
    "        return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tap_features_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    tap_features_df = load_dataframe(\"tap_features_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (tap_features_df is None):\n",
    "        tap_features_df = build_tap_features_df()\n",
    "        save_dataframe(tap_features_df)\n",
    "\n",
    "    return tap_features_df\n",
    "\n",
    "\n",
    "def build_tap_features_df():\n",
    "\n",
    "    print(\"Building tap_features_df...\")\n",
    "\n",
    "    # list of tap feature dfs, one for each event, to be concatenated at the end\n",
    "    tap_feature_dfs = list()\n",
    "\n",
    "    # Get tap_df\n",
    "    tap_df = get_tap_df()\n",
    "\n",
    "    # Get tap events\n",
    "    events = tap_df['event_no'].unique()\n",
    "\n",
    "    # For each event get features dataframe and append to list\n",
    "    for event in events:\n",
    "        tap_event_df = tap_df[tap_df['event_no'] == event]\n",
    "        tap_event_df = TapEvent(tap_event_df).get_feature_dataframe()\n",
    "        tap_feature_dfs.append(tap_event_df)\n",
    "\n",
    "    # concatenate all tap features into a single dataframe\n",
    "    tap_features_df = pd.concat(tap_feature_dfs)\n",
    "\n",
    "    # Replace Not a Number (NaN) with zero\n",
    "    tap_features_df = tap_features_df.fillna(0)\n",
    "\n",
    "    # Replace infinite values with 0\n",
    "    tap_features_df = tap_features_df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # Reset Indexes\n",
    "    tap_features_df = tap_features_df.reset_index()\n",
    "\n",
    "    # Remove redundant Index column\n",
    "    tap_features_df = tap_features_df.drop(columns=['index'])\n",
    "\n",
    "    return tap_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tap_features_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Zoom Features\n",
    "\n",
    "define featuress in `ZoomEvent`\n",
    "define `get_zoom_features_df()` to build `zoom_features_df` from data or retrieve it from Checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZoomEvent:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index()\n",
    "        # event df of first finger\n",
    "        self.f1_df = self.df[self.df['pid'] == self.df['pid'].iloc[0]]\n",
    "        self.f1_df = self.f1_df.reset_index()\n",
    "        # event df of second finger\n",
    "        self.f2_df = self.df[self.df['pid'] != self.df['pid'].iloc[0]]\n",
    "        self.f2_df = self.f2_df.reset_index()\n",
    "\n",
    "    def get_feature_dataframe(self):\n",
    "        if not self.is_valid():\n",
    "            return None\n",
    "        return pd.DataFrame(self.get_all_feature_values(), index=[0])\n",
    "\n",
    "    # Validate if the current Zoom Event is valid\n",
    "    def is_valid(self):\n",
    "        # two pointers captured (and only 2)\n",
    "        if self.df['pid'].nunique() == 2:\n",
    "            # two fingers down, moved, and two fingers up\n",
    "            desired_actions = ['DOWN-1ST', 'DOWN-P2',\n",
    "                               'MOVE', 'UP-P2', 'UP-LAST']\n",
    "            if all(action in self.df['action'].unique() for action in desired_actions):\n",
    "                # distance must have changed\n",
    "                start_distance = ZoomEvent.get_starting_distance_between_fingers(\n",
    "                    self.f1_df, self.f2_df)\n",
    "                end_distance = ZoomEvent.get_ending_distance_between_fingers(\n",
    "                    self.f1_df, self.f2_df)\n",
    "                if start_distance != end_distance:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def get_all_feature_values(self):\n",
    "        feature_values = {}\n",
    "\n",
    "        # Parent DataFrame\n",
    "        feature_values['gesture'] = 'zoom'\n",
    "        feature_values['direction'] = ZoomEvent.get_direction(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['event_no'] = ZoomEvent.get_event_no(self.df)\n",
    "        feature_values['session_id'] = ZoomEvent.get_session_id(self.df)\n",
    "        feature_values['user_id'] = ZoomEvent.get_user_id(self.df)\n",
    "        feature_values['device_type'] = ZoomEvent.get_device_type(self.df)\n",
    "        feature_values['age'] = ZoomEvent.get_age(self.df)\n",
    "        feature_values['age_group'] = ZoomEvent.get_age_group(self.df)\n",
    "\n",
    "        # Size Features\n",
    "        feature_values['start_size_finger_1'] = ZoomEvent.get_start_size(\n",
    "            self.f1_df)\n",
    "        feature_values['end_size_finger_1'] = ZoomEvent.get_end_size(\n",
    "            self.f1_df)\n",
    "        feature_values['max_size_finger_1'] = ZoomEvent.get_max_size(\n",
    "            self.f1_df)\n",
    "        feature_values['min_size_finger_1'] = ZoomEvent.get_min_size(\n",
    "            self.f1_df)\n",
    "        feature_values['avg_size_finger_1'] = ZoomEvent.get_avg_size(\n",
    "            self.f1_df)\n",
    "        feature_values['range_in_size_finger_1'] = ZoomEvent.get_range_in_size(\n",
    "            self.f1_df)\n",
    "        feature_values['start_size_finger_2'] = ZoomEvent.get_start_size(\n",
    "            self.f2_df)\n",
    "        feature_values['end_size_finger_2'] = ZoomEvent.get_end_size(\n",
    "            self.f2_df)\n",
    "        feature_values['max_size_finger_2'] = ZoomEvent.get_max_size(\n",
    "            self.f2_df)\n",
    "        feature_values['min_size_finger_2'] = ZoomEvent.get_min_size(\n",
    "            self.f2_df)\n",
    "        feature_values['avg_size_finger_2'] = ZoomEvent.get_avg_size(\n",
    "            self.f2_df)\n",
    "        feature_values['range_in_size_finger_2'] = ZoomEvent.get_range_in_size(\n",
    "            self.f2_df)\n",
    "        feature_values['difference_in_max_Sizes'] = ZoomEvent.get_diff_in_max_size(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['difference_in_min_Sizes'] = ZoomEvent.get_diff_in_min_size(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['difference_in_avg_Sizes'] = ZoomEvent.get_diff_in_avg_size(\n",
    "            self.f1_df, self.f2_df)\n",
    "\n",
    "        # Pressure Features\n",
    "        feature_values['start_pressure_finger_1'] = ZoomEvent.get_start_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['end_pressure_finger_1'] = ZoomEvent.get_end_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['max_pressure_finger_1'] = ZoomEvent.get_max_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['min_pressure_finger_1'] = ZoomEvent.get_min_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['avg_pressure_finger_1'] = ZoomEvent.get_avg_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['range_in_pressure_finger_1'] = ZoomEvent.get_range_in_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['start_pressure_finger_2'] = ZoomEvent.get_start_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['end_pressure_finger_2'] = ZoomEvent.get_end_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['max_pressure_finger_2'] = ZoomEvent.get_max_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['min_pressure_finger_2'] = ZoomEvent.get_min_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['avg_pressure_finger_2'] = ZoomEvent.get_avg_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['range_in_pressure_finger_2'] = ZoomEvent.get_range_in_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['difference_in_max_Pressures'] = ZoomEvent.get_diff_in_max_pressure(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['difference_in_min_Pressures'] = ZoomEvent.get_diff_in_min_pressure(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['difference_in_avg_Pressures'] = ZoomEvent.get_diff_in_avg_pressure(\n",
    "            self.f1_df, self.f2_df)\n",
    "\n",
    "        # Velocity Features\n",
    "        feature_values['start_velocity_x_finger_1'] = ZoomEvent.get_start_vx(\n",
    "            self.f1_df)\n",
    "        feature_values['start_velocity_y_finger_1'] = ZoomEvent.get_start_vy(\n",
    "            self.f1_df)\n",
    "        feature_values['end_velocity_x_finger_1'] = ZoomEvent.get_end_vx(\n",
    "            self.f1_df)\n",
    "        feature_values['end_Velocuty y_finger_1'] = ZoomEvent.get_end_vy(\n",
    "            self.f1_df)\n",
    "        feature_values['max_velocity_x_finger_1'] = ZoomEvent.get_max_vx(\n",
    "            self.f1_df)\n",
    "        feature_values['max_velocity_y_finger_1'] = ZoomEvent.get_max_vy(\n",
    "            self.f1_df)\n",
    "        feature_values['min_velocity_x_finger_1'] = ZoomEvent.get_min_vx(\n",
    "            self.f1_df)\n",
    "        feature_values['min_velocity_y_finger_1'] = ZoomEvent.get_min_vy(\n",
    "            self.f1_df)\n",
    "        feature_values['avg_velocity_x_finger_1'] = ZoomEvent.get_avg_vx(\n",
    "            self.f1_df)\n",
    "        feature_values['avg_velocity_y_finger_1'] = ZoomEvent.get_avg_vy(\n",
    "            self.f1_df)\n",
    "        feature_values['range_in_velocity_x_finger_1'] = ZoomEvent.get_range_in_vx(\n",
    "            self.f1_df)\n",
    "        feature_values['range_in_velocity_y_finger_1'] = ZoomEvent.get_range_in_vy(\n",
    "            self.f1_df)\n",
    "        feature_values['start_velocity_x_finger_2'] = ZoomEvent.get_start_vx(\n",
    "            self.f2_df)\n",
    "        feature_values['start_velocity_y_finger_2'] = ZoomEvent.get_start_vy(\n",
    "            self.f2_df)\n",
    "        feature_values['end_velocity_x_finger_2'] = ZoomEvent.get_end_vx(\n",
    "            self.f2_df)\n",
    "        feature_values['end_velocity_y_finger_2'] = ZoomEvent.get_end_vy(\n",
    "            self.f2_df)\n",
    "        feature_values['max_velocity_x_finger_2'] = ZoomEvent.get_max_vx(\n",
    "            self.f2_df)\n",
    "        feature_values['max_velocity_y_finger_2'] = ZoomEvent.get_max_vy(\n",
    "            self.f2_df)\n",
    "        feature_values['min_velocity_x_finger_2'] = ZoomEvent.get_min_vx(\n",
    "            self.f2_df)\n",
    "        feature_values['min_velocity_y_finger_2'] = ZoomEvent.get_min_vy(\n",
    "            self.f2_df)\n",
    "        feature_values['avg_velocity_x_finger_2'] = ZoomEvent.get_avg_vx(\n",
    "            self.f2_df)\n",
    "        feature_values['avg_velocity_y_finger_2'] = ZoomEvent.get_avg_vy(\n",
    "            self.f2_df)\n",
    "        feature_values['range_in_velocity_x_finger_2'] = ZoomEvent.get_range_in_vx(\n",
    "            self.f2_df)\n",
    "        feature_values['range_in_velocity_y_finger_2'] = ZoomEvent.get_range_in_vy(\n",
    "            self.f2_df)\n",
    "        feature_values['difference_in_max_velocities_x'] = ZoomEvent.get_diff_in_max_vx(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['difference_in_max_velocities_y'] = ZoomEvent.get_diff_in_max_vy(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['difference_in_min_velocities_x'] = ZoomEvent.get_diff_in_min_vx(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['difference_in_min_velocities_y'] = ZoomEvent.get_diff_in_min_vy(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['difference_in_avg_velocities_x'] = ZoomEvent.get_diff_in_avg_vx(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['difference_in_avg_velocities_y'] = ZoomEvent.get_diff_in_avg_vy(\n",
    "            self.f1_df, self.f2_df)\n",
    "\n",
    "        # Distance Features\n",
    "        feature_values['total_distance_finger_1'] = ZoomEvent.get_total_distance(\n",
    "            self.f1_df)\n",
    "        feature_values['distance_to_max_pressure_finger_1'] = ZoomEvent.get_distance_start_max_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['distance_to_min_pressure_finger_1'] = ZoomEvent.get_distance_start_min_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['total_distance_finger_2'] = ZoomEvent.get_total_distance(\n",
    "            self.f2_df)\n",
    "        feature_values['distance_to_max_pressure_finger_2'] = ZoomEvent.get_distance_start_max_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['distance_to_min_pressure_finger_2'] = ZoomEvent.get_distance_start_min_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['starting_distance_between_fingers'] = ZoomEvent.get_starting_distance_between_fingers(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['ending_distance_between_fingers'] = ZoomEvent.get_ending_distance_between_fingers(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['difference_in_total_distances'] = ZoomEvent.get_diff_in_distance(\n",
    "            self.f1_df, self.f2_df)\n",
    "\n",
    "        # Time Features\n",
    "        feature_values['total_Duration'] = ZoomEvent.get_hold_time(self.df)\n",
    "        feature_values['hold_time_finger_1'] = ZoomEvent.get_hold_time(\n",
    "            self.f1_df)\n",
    "        feature_values['time_to_max_pressure_finger_1'] = ZoomEvent.get_time_to_max_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['time_to_min_pressure_finger_1'] = ZoomEvent.get_time_to_min_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['hold_time_finger_2'] = ZoomEvent.get_hold_time(\n",
    "            self.f2_df)\n",
    "        feature_values['time_to_max_pressure_finger_2'] = ZoomEvent.get_time_to_max_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['time_to_min_pressure_finger_2'] = ZoomEvent.get_time_to_min_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['difference_in_hold_times'] = ZoomEvent.get_diff_in_hold_time(\n",
    "            self.f1_df, self.f2_df)\n",
    "\n",
    "        # Product Features\n",
    "        feature_values['product_of_max_size_and_max_pressure_finger_1'] = ZoomEvent.get_product_max_size_max_pressure(\n",
    "            self.f1_df)\n",
    "        feature_values['product_of_max_size_and_hold_time_finger_1'] = ZoomEvent.get_product_max_size_hold_time(\n",
    "            self.f1_df)\n",
    "        feature_values['product_of_min_size_and_hold_time_finger_1'] = ZoomEvent.get_product_min_size_hold_time(\n",
    "            self.f1_df)\n",
    "        feature_values['product_of_avg_size_and_hold_time_finger_1'] = ZoomEvent.get_product_avg_size_hold_time(\n",
    "            self.f1_df)\n",
    "        feature_values['product_of_max_size_and_max_pressure_finger_2'] = ZoomEvent.get_product_max_size_max_pressure(\n",
    "            self.f2_df)\n",
    "        feature_values['product_of_max_size_and_hold_time_finger_2'] = ZoomEvent.get_product_max_size_hold_time(\n",
    "            self.f2_df)\n",
    "        feature_values['product_of_min_size_and_hold_time_finger_2'] = ZoomEvent.get_product_min_size_hold_time(\n",
    "            self.f2_df)\n",
    "        feature_values['product_of_avg_size_and_hold_time_finger_2'] = ZoomEvent.get_product_avg_size_hold_time(\n",
    "            self.f2_df)\n",
    "\n",
    "        # Slope Features\n",
    "        feature_values['slope_start_to_end_finger_1'] = ZoomEvent.get_slope_start_end(\n",
    "            self.f1_df)\n",
    "        feature_values['slope_start_to_median_finger_1'] = ZoomEvent.get_slope_start_median(\n",
    "            self.f1_df)\n",
    "        feature_values['slope_median_to_end_finger_1'] = ZoomEvent.get_slope_median_end(\n",
    "            self.f1_df)\n",
    "        feature_values['slope_start_to_end_finger_2'] = ZoomEvent.get_slope_start_end(\n",
    "            self.f2_df)\n",
    "        feature_values['slope_start_to_median_finger_2'] = ZoomEvent.get_slope_start_median(\n",
    "            self.f2_df)\n",
    "        feature_values['slope_median_to_end_finger_2'] = ZoomEvent.get_slope_median_end(\n",
    "            self.f2_df)\n",
    "        feature_values['avg_of_slopes_start_to_End'] = ZoomEvent.get_avg_slope_start_end(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['avg_of_slopes_start_to_Median'] = ZoomEvent.get_avg_slope_start_median(\n",
    "            self.f1_df, self.f2_df)\n",
    "        feature_values['avg_of_slopes_median_to_End'] = ZoomEvent.get_avg_slope_median_end(\n",
    "            self.f1_df, self.f2_df)\n",
    "\n",
    "        return feature_values\n",
    "\n",
    "    # Helper Methods -------------------------------------------------------------\n",
    "\n",
    "    # Data from parent DataFrame\n",
    "\n",
    "    def get_event_no(df):\n",
    "        return df['event_no'].iloc[0]\n",
    "\n",
    "    def get_session_id(df):\n",
    "        return df['session_id'].iloc[0]\n",
    "\n",
    "    def get_user_id(df):\n",
    "        return df['user_id'].iloc[0]\n",
    "\n",
    "    def get_device_type(df):\n",
    "        return df['device_type'].iloc[0]\n",
    "\n",
    "    def get_age(df):\n",
    "        return df['age'].iloc[0]\n",
    "\n",
    "    def get_age_group(df):\n",
    "        return df['age_group'].iloc[0]\n",
    "\n",
    "    # Direction Feature\n",
    "    def get_direction(f1_df, f2_df):\n",
    "        start_distance = ZoomEvent.get_starting_distance_between_fingers(\n",
    "            f1_df, f2_df)\n",
    "        end_distance = ZoomEvent.get_ending_distance_between_fingers(\n",
    "            f1_df, f2_df)\n",
    "        if start_distance < end_distance:  # Distance is increasing\n",
    "            direction = 'zoom-in'\n",
    "        elif start_distance > end_distance:  # Distance is decreasing\n",
    "            direction = 'zoom-out'\n",
    "        return direction\n",
    "\n",
    "    # Size Features\n",
    "    def get_start_size(df):\n",
    "        return df['size'].iloc[0]\n",
    "\n",
    "    def get_end_size(df):\n",
    "        return df['size'].iloc[-1]\n",
    "\n",
    "    def get_max_size(df):\n",
    "        return df['size'].max()\n",
    "\n",
    "    def get_min_size(df):\n",
    "        return df['size'].min()\n",
    "\n",
    "    def get_avg_size(df):\n",
    "        return df['size'].mean()\n",
    "\n",
    "    def get_diff_in_max_size(f1_df, f2_df):\n",
    "        return abs(ZoomEvent.get_max_size(f1_df) - ZoomEvent.get_max_size(f2_df))\n",
    "\n",
    "    def get_diff_in_min_size(f1_df, f2_df):\n",
    "        return abs(ZoomEvent.get_min_size(f1_df) - ZoomEvent.get_min_size(f2_df))\n",
    "\n",
    "    def get_diff_in_avg_size(f1_df, f2_df):\n",
    "        return abs(ZoomEvent.get_avg_size(f1_df) - ZoomEvent.get_avg_size(f2_df))\n",
    "\n",
    "    def get_range_in_size(df):\n",
    "        return abs(ZoomEvent.get_max_size(df) - ZoomEvent.get_min_size(df))\n",
    "\n",
    "    # Pressure Features\n",
    "    def get_start_pressure(df):\n",
    "        return df['pressure'].iloc[0]\n",
    "\n",
    "    def get_end_pressure(df):\n",
    "        return df['pressure'].iloc[-1]\n",
    "\n",
    "    def get_max_pressure(df):\n",
    "        return df['pressure'].max()\n",
    "\n",
    "    def get_min_pressure(df):\n",
    "        return df['pressure'].min()\n",
    "\n",
    "    def get_avg_pressure(df):\n",
    "        return df['pressure'].mean()\n",
    "\n",
    "    def get_diff_in_max_pressure(f1_df, f2_df):\n",
    "        return abs(ZoomEvent.get_max_pressure(f1_df) - ZoomEvent.get_max_pressure(f2_df))\n",
    "\n",
    "    def get_diff_in_min_pressure(f1_df, f2_df):\n",
    "        return abs(ZoomEvent.get_min_pressure(f1_df) - ZoomEvent.get_min_pressure(f2_df))\n",
    "\n",
    "    def get_diff_in_avg_pressure(f1_df, f2_df):\n",
    "        return abs(ZoomEvent.get_avg_pressure(f1_df) - ZoomEvent.get_avg_pressure(f2_df))\n",
    "\n",
    "    def get_range_in_pressure(df):\n",
    "        return abs(ZoomEvent.get_max_pressure(df) - ZoomEvent.get_min_pressure(df))\n",
    "\n",
    "    # Velocity Features\n",
    "    def get_start_vx(df):\n",
    "        return df['vx'].iloc[0]\n",
    "\n",
    "    def get_end_vx(df):\n",
    "        return df['vx'].iloc[-1]\n",
    "\n",
    "    def get_max_vx(df):\n",
    "        return df['vx'].max()\n",
    "\n",
    "    def get_min_vx(df):\n",
    "        return df['vx'].min()\n",
    "\n",
    "    def get_avg_vx(df):\n",
    "        return df['vx'].mean()\n",
    "\n",
    "    def get_start_vy(df):\n",
    "        return df['vy'].iloc[0]\n",
    "\n",
    "    def get_end_vy(df):\n",
    "        return df['vy'].iloc[-1]\n",
    "\n",
    "    def get_max_vy(df):\n",
    "        return df['vy'].max()\n",
    "\n",
    "    def get_min_vy(df):\n",
    "        return df['vy'].min()\n",
    "\n",
    "    def get_avg_vy(df):\n",
    "        return df['vy'].mean()\n",
    "\n",
    "    def get_range_in_vx(df):\n",
    "        max_vx = ZoomEvent.get_max_vx(df)\n",
    "        min_vx = ZoomEvent.get_min_vx(df)\n",
    "        if max_vx == float('Inf') or min_vx == float('Inf'):\n",
    "            return float('Inf')\n",
    "        elif max_vx == float('NaN') or min_vx == float('NaN'):\n",
    "            return float('NaN')\n",
    "        else:\n",
    "            return abs(max_vx - min_vx)\n",
    "\n",
    "    def get_range_in_vy(df):\n",
    "        max_vy = ZoomEvent.get_max_vy(df)\n",
    "        min_vy = ZoomEvent.get_min_vy(df)\n",
    "        if max_vy == float('Inf') or min_vy == float('Inf'):\n",
    "            return float('Inf')\n",
    "        elif max_vy == float('NaN') or min_vy == float('NaN'):\n",
    "            return float('NaN')\n",
    "        else:\n",
    "            return abs(max_vy - min_vy)\n",
    "\n",
    "    def get_diff_in_max_vx(f1_df, f2_df):\n",
    "        max_vx_f1 = ZoomEvent.get_max_vx(f1_df)\n",
    "        max_vx_f2 = ZoomEvent.get_max_vx(f2_df)\n",
    "        if max_vx_f1 == float('Inf') or max_vx_f2 == float('Inf'):\n",
    "            return float('Inf')\n",
    "        elif max_vx_f1 == float('NaN') or max_vx_f2 == float('NaN'):\n",
    "            return float('NaN')\n",
    "        else:\n",
    "            return abs(ZoomEvent.get_max_vx(f1_df) - ZoomEvent.get_max_vx(f2_df))\n",
    "\n",
    "    def get_diff_in_min_vx(f1_df, f2_df):\n",
    "        min_vx_f1 = ZoomEvent.get_min_vx(f1_df)\n",
    "        min_vx_f2 = ZoomEvent.get_min_vx(f2_df)\n",
    "        if min_vx_f1 == float('Inf') or min_vx_f2 == float('Inf'):\n",
    "            return float('Inf')\n",
    "        elif min_vx_f1 == float('NaN') or min_vx_f2 == float('NaN'):\n",
    "            return float('NaN')\n",
    "        else:\n",
    "            return abs(ZoomEvent.get_min_vx(f1_df) - ZoomEvent.get_min_vx(f2_df))\n",
    "\n",
    "    def get_diff_in_avg_vx(f1_df, f2_df):\n",
    "        avg_vx_f1 = ZoomEvent.get_avg_vx(f1_df)\n",
    "        avg_vx_f2 = ZoomEvent.get_avg_vx(f2_df)\n",
    "        if avg_vx_f1 == float('Inf') or avg_vx_f2 == float('Inf'):\n",
    "            return float('Inf')\n",
    "        elif avg_vx_f1 == float('NaN') or avg_vx_f2 == float('NaN'):\n",
    "            return float('NaN')\n",
    "        else:\n",
    "            return abs(ZoomEvent.get_avg_vx(f1_df) - ZoomEvent.get_avg_vx(f2_df))\n",
    "\n",
    "    def get_diff_in_max_vy(f1_df, f2_df):\n",
    "        max_vy_f1 = ZoomEvent.get_max_vy(f1_df)\n",
    "        max_vy_f2 = ZoomEvent.get_max_vy(f2_df)\n",
    "        if max_vy_f1 == float('Inf') or max_vy_f2 == float('Inf'):\n",
    "            return float('Inf')\n",
    "        elif max_vy_f1 == float('NaN') or max_vy_f2 == float('NaN'):\n",
    "            return float('NaN')\n",
    "        else:\n",
    "            return abs(ZoomEvent.get_max_vy(f1_df) - ZoomEvent.get_max_vy(f2_df))\n",
    "\n",
    "    def get_diff_in_min_vy(f1_df, f2_df):\n",
    "        min_vy_f1 = ZoomEvent.get_min_vy(f1_df)\n",
    "        min_vy_f2 = ZoomEvent.get_min_vy(f2_df)\n",
    "        if min_vy_f1 == float('Inf') or min_vy_f2 == float('Inf'):\n",
    "            return float('Inf')\n",
    "        elif min_vy_f1 == float('NaN') or min_vy_f2 == float('NaN'):\n",
    "            return float('NaN')\n",
    "        else:\n",
    "            return abs(ZoomEvent.get_min_vy(f1_df) - ZoomEvent.get_min_vy(f2_df))\n",
    "\n",
    "    def get_diff_in_avg_vy(f1_df, f2_df):\n",
    "        avg_vy_f1 = ZoomEvent.get_avg_vy(f1_df)\n",
    "        avg_vy_f2 = ZoomEvent.get_avg_vy(f2_df)\n",
    "        if avg_vy_f1 == float('Inf') or avg_vy_f2 == float('Inf'):\n",
    "            return float('Inf')\n",
    "        elif avg_vy_f1 == float('NaN') or avg_vy_f2 == float('NaN'):\n",
    "            return float('NaN')\n",
    "        else:\n",
    "            return abs(ZoomEvent.get_avg_vy(f1_df) - ZoomEvent.get_avg_vy(f2_df))\n",
    "\n",
    "    # Distance Features\n",
    "    def get_total_distance(df):\n",
    "        x1, y1 = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        x2, y2 = df['x'].iloc[-1], df['y'].iloc[-1]\n",
    "        distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        return distance\n",
    "\n",
    "    def get_starting_distance_between_fingers(f1_df, f2_df):\n",
    "        f1_x, f1_y = f1_df['x'].iloc[0], f1_df['y'].iloc[0]\n",
    "        f2_x, f2_y = f2_df['x'].iloc[0], f2_df['y'].iloc[0]\n",
    "        distance = math.sqrt((f2_x - f1_x)**2 + (f2_y - f1_y)**2)\n",
    "        return distance\n",
    "\n",
    "    def get_ending_distance_between_fingers(f1_df, f2_df):\n",
    "        f1_x, f1_y = f1_df['x'].iloc[-1], f1_df['y'].iloc[-1]\n",
    "        f2_x, f2_y = f2_df['x'].iloc[-1], f2_df['y'].iloc[-1]\n",
    "        distance = math.sqrt((f2_x - f1_x)**2 + (f2_y - f1_y)**2)\n",
    "        return distance\n",
    "\n",
    "    def get_distance_start_max_pressure(df):\n",
    "        start_x, start_y = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        max_pressure_index = df['pressure'].idxmax()\n",
    "        max_pressure_x = df['x'].iloc[max_pressure_index]\n",
    "        max_pressure_y = df['y'].iloc[max_pressure_index]\n",
    "        distance = math.sqrt((max_pressure_x - start_x) **\n",
    "                             2 + (max_pressure_y - start_y)**2)\n",
    "        return distance\n",
    "\n",
    "    def get_distance_start_min_pressure(df):\n",
    "        start_x, start_y = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        min_pressure_index = df['pressure'].idxmin()\n",
    "        min_pressure_x = df['x'].iloc[min_pressure_index]\n",
    "        min_pressure_y = df['y'].iloc[min_pressure_index]\n",
    "        distance = math.sqrt((min_pressure_x - start_x) **\n",
    "                             2 + (min_pressure_y - start_y)**2)\n",
    "        return distance\n",
    "\n",
    "    def get_diff_in_distance(f1_df, f2_df):\n",
    "        return abs(ZoomEvent.get_total_distance(f2_df) - ZoomEvent.get_total_distance(f1_df))\n",
    "\n",
    "    # Time Features\n",
    "    def get_time_to_max_pressure(df):\n",
    "        max_pressure_index = df['pressure'].idxmax()\n",
    "        time_to_max_pressure = df['mille'].iloc[max_pressure_index] - \\\n",
    "            df['mille'].iloc[0]\n",
    "        return time_to_max_pressure\n",
    "\n",
    "    def get_time_to_min_pressure(df):\n",
    "        min_pressure_index = df['pressure'].idxmin()\n",
    "        time_to_min_pressure = df['mille'].iloc[min_pressure_index] - \\\n",
    "            df['mille'].iloc[0]\n",
    "        return time_to_min_pressure\n",
    "\n",
    "    def get_hold_time(df):\n",
    "        total_duration = df['mille'].iloc[-1] - df['mille'].iloc[0]\n",
    "        return total_duration\n",
    "\n",
    "    def get_diff_in_hold_time(f1_df, f2_df):\n",
    "        return abs(ZoomEvent.get_hold_time(f1_df) - ZoomEvent.get_hold_time(f2_df))\n",
    "\n",
    "    # Product Features\n",
    "    def get_product_max_size_max_pressure(df):\n",
    "        return ZoomEvent.get_max_size(df) * ZoomEvent.get_max_pressure(df)\n",
    "\n",
    "    def get_product_avg_size_hold_time(df):\n",
    "        return ZoomEvent.get_avg_size(df) * ZoomEvent.get_hold_time(df)\n",
    "\n",
    "    def get_product_max_size_hold_time(df):\n",
    "        return ZoomEvent.get_max_size(df) * ZoomEvent.get_hold_time(df)\n",
    "\n",
    "    def get_product_min_size_hold_time(df):\n",
    "        return ZoomEvent.get_min_size(df) * ZoomEvent.get_hold_time(df)\n",
    "\n",
    "    # Slope Features\n",
    "    def get_slope_start_end(df):\n",
    "        x1, y1 = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        x2, y2 = df['x'].iloc[-1], df['y'].iloc[-1]\n",
    "        if x2 - x1 != 0:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "        else:\n",
    "            slope = 0  # vertical slope is undefined\n",
    "        return slope\n",
    "\n",
    "    def get_slope_start_median(df):\n",
    "        x1, y1 = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        median_index = len(df) // 2\n",
    "        x_median = df['x'].iloc[median_index]\n",
    "        y_median = df['y'].iloc[median_index]\n",
    "        if x_median - x1 != 0:\n",
    "            slope = (y_median - y1) / (x_median - x1)\n",
    "        else:\n",
    "            slope = 0  # vertical slope is undefined\n",
    "        return slope\n",
    "\n",
    "    def get_slope_median_end(df):\n",
    "        median_index = len(df) // 2\n",
    "        x_median = df['x'].iloc[median_index]\n",
    "        y_median = df['y'].iloc[median_index]\n",
    "        x_end = df['x'].iloc[-1]\n",
    "        y_end = df['y'].iloc[-1]\n",
    "        if x_end - x_median != 0:\n",
    "            slope = (y_end - y_median) / (x_end - x_median)\n",
    "        else:\n",
    "            slope = 0  # vertical slope is undefined\n",
    "        return slope\n",
    "\n",
    "    def get_avg_slope_start_end(f1_df, f2_df):\n",
    "        return (ZoomEvent.get_slope_start_end(f1_df) + ZoomEvent.get_slope_start_end(f2_df)) / 2\n",
    "\n",
    "    def get_avg_slope_start_median(f1_df, f2_df):\n",
    "        return (ZoomEvent.get_slope_start_median(f1_df) + ZoomEvent.get_slope_start_median(f2_df)) / 2\n",
    "\n",
    "    def get_avg_slope_median_end(f1_df, f2_df):\n",
    "        return (ZoomEvent.get_slope_median_end(f1_df) + ZoomEvent.get_slope_median_end(f2_df)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zoom_features_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    zoom_features_df = load_dataframe(\"zoom_features_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (zoom_features_df is None):\n",
    "        zoom_features_df = build_zoom_features_df()\n",
    "        save_dataframe(zoom_features_df)\n",
    "\n",
    "    return zoom_features_df\n",
    "\n",
    "\n",
    "def build_zoom_features_df():\n",
    "\n",
    "    print(\"Building zoom_features_df...\")\n",
    "\n",
    "    # list of zoom feature dfs, one for each event, to be concatenated at the end\n",
    "    zoom_feature_dfs = list()\n",
    "\n",
    "    # Get zoom_df\n",
    "    zoom_df = get_zoom_df()\n",
    "\n",
    "    # Get zoom events\n",
    "    events = zoom_df['event_no'].unique()\n",
    "\n",
    "    # For each event get features dataframe and append to list\n",
    "    for event in events:\n",
    "        zoom_event_df = zoom_df[zoom_df['event_no'] == event]\n",
    "        zoom_event_df = ZoomEvent(zoom_event_df).get_feature_dataframe()\n",
    "        zoom_feature_dfs.append(zoom_event_df)\n",
    "\n",
    "    # concatenate all zoom features into a single dataframe\n",
    "    zoom_features_df = pd.concat(zoom_feature_dfs)\n",
    "\n",
    "    # Replace Not a Number (NaN) with zero\n",
    "    zoom_features_df = zoom_features_df.fillna(0)\n",
    "\n",
    "    # Replace infinite values with 0\n",
    "    zoom_features_df = zoom_features_df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # Reset Indexes\n",
    "    zoom_features_df = zoom_features_df.reset_index()\n",
    "\n",
    "    # Remove redundant Index column\n",
    "    zoom_features_df = zoom_features_df.drop(columns=['index'])\n",
    "\n",
    "    return zoom_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_zoom_features_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Swipe Features\n",
    "\n",
    "define features in `SwipeEvent`\n",
    "define `get_swipe_features_df()` to build `swipe_features_df` from data or retrieve it from Checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwipeEvent:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index()\n",
    "\n",
    "    def get_feature_dataframe(self):\n",
    "        if not self.is_valid():\n",
    "            return None\n",
    "        return pd.DataFrame(SwipeEvent.get_all_feature_values(self), index=['i',])\n",
    "\n",
    "    # Validate input touch event if only 1 pointer, starts with Down, and ends with Up\n",
    "    def is_valid(self):\n",
    "        if self.df['pid'].nunique() == 1:\n",
    "            if (self.df['action'].iloc[0] == 'DOWN-1ST') \\\n",
    "                    and (self.df['action'].iloc[-1] == 'UP-LAST') \\\n",
    "                    and ((self.df['action'] == 'MOVE').any()):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_all_feature_values(self):\n",
    "        feature_values = {}\n",
    "\n",
    "        # Parent DataFrame\n",
    "        feature_values['gesture'] = 'swipe'\n",
    "        feature_values['orientation'] = SwipeEvent.get_orientation(self.df)\n",
    "        feature_values['direction'] = SwipeEvent.get_direction(self.df)\n",
    "        feature_values['event_no'] = SwipeEvent.get_event_no(self.df)\n",
    "        feature_values['session_id'] = SwipeEvent.get_session_id(self.df)\n",
    "        feature_values['user_id'] = SwipeEvent.get_user_id(self.df)\n",
    "        feature_values['device_type'] = SwipeEvent.get_device_type(self.df)\n",
    "        feature_values['age'] = SwipeEvent.get_age(self.df)\n",
    "        feature_values['age_group'] = SwipeEvent.get_age_group(self.df)\n",
    "\n",
    "        # Size Features\n",
    "        feature_values['start_size'] = SwipeEvent.get_start_size(self.df)\n",
    "        feature_values['end_size'] = SwipeEvent.get_end_size(self.df)\n",
    "        feature_values['max_size'] = SwipeEvent.get_max_size(self.df)\n",
    "        feature_values['min_size'] = SwipeEvent.get_min_size(self.df)\n",
    "        feature_values['avg_size'] = SwipeEvent.get_avg_size(self.df)\n",
    "        feature_values['range_in_size'] = SwipeEvent.get_range_in_size(self.df)\n",
    "\n",
    "        # Pressure Features\n",
    "        feature_values['start_press'] = SwipeEvent.get_start_pressure(self.df)\n",
    "        feature_values['end_press'] = SwipeEvent.get_end_pressure(self.df)\n",
    "        feature_values['max_press'] = SwipeEvent.get_max_pressure(self.df)\n",
    "        feature_values['min_press'] = SwipeEvent.get_min_pressure(self.df)\n",
    "        feature_values['avg_press'] = SwipeEvent.get_avg_pressure(self.df)\n",
    "        feature_values['range_in_pressure'] = SwipeEvent.get_range_in_pressure(\n",
    "            self.df)\n",
    "\n",
    "        # Velocity Features\n",
    "        feature_values['first_non_zero_velocity_main_axis'] = SwipeEvent.get_first_non_zero_velocity_main_axis(\n",
    "            self.df)\n",
    "        feature_values['first_non_zero_velocity_cross_axis'] = SwipeEvent.get_first_non_zero_velocity_cross_axis(\n",
    "            self.df)\n",
    "        feature_values['last_non_zero_velocity_main_axis'] = SwipeEvent.get_last_non_zero_velocity_main_axis(\n",
    "            self.df)\n",
    "        feature_values['last_non_zero_velocity_cross_axis'] = SwipeEvent.get_last_non_zero_velocity_cross_axis(\n",
    "            self.df)\n",
    "        feature_values['start_velocity_main_axis'] = SwipeEvent.get_start_velocity_main_axis(\n",
    "            self.df)\n",
    "        feature_values['start_velocity_cross_axis'] = SwipeEvent.get_start_velocity_cross_axis(\n",
    "            self.df)\n",
    "        feature_values['end_velocity_main_axis'] = SwipeEvent.get_end_velocity_main_axis(\n",
    "            self.df)\n",
    "        feature_values['end_velocity_cross_axis'] = SwipeEvent.get_end_velocity_cross_axis(\n",
    "            self.df)\n",
    "        feature_values['min_velocity_main_axis'] = SwipeEvent.get_min_velocity_main_axis(\n",
    "            self.df)\n",
    "        feature_values['min_velocity_cross_axis'] = SwipeEvent.get_min_velocity_cross_axis(\n",
    "            self.df)\n",
    "        feature_values['max_velocity_main_axis'] = SwipeEvent.get_max_velocity_main_axis(\n",
    "            self.df)\n",
    "        feature_values['max_velocity_cross_axis'] = SwipeEvent.get_max_velocity_cross_axis(\n",
    "            self.df)\n",
    "        feature_values['avg_velocity_main_axis'] = SwipeEvent.get_avg_velocity_main_axis(\n",
    "            self.df)\n",
    "        feature_values['avg_velocity_cross_axis'] = SwipeEvent.get_avg_velocity_cross_axis(\n",
    "            self.df)\n",
    "        feature_values['range_in_velocity_main_axis'] = SwipeEvent.get_range_in_velocity_main_axis(\n",
    "            self.df)\n",
    "        feature_values['range_in_velocity_cross_axis'] = SwipeEvent.get_range_in_velocity_cross_axis(\n",
    "            self.df)\n",
    "\n",
    "        # Speed Feature\n",
    "        feature_values['speed'] = SwipeEvent.get_speed(self.df)\n",
    "\n",
    "        # Distance Features\n",
    "        feature_values['total_distance'] = SwipeEvent.get_total_distance(\n",
    "            self.df)\n",
    "        feature_values['distance_to_max_pressure'] = SwipeEvent.get_distance_start_max_pressure(\n",
    "            self.df)\n",
    "        feature_values['distance_to_min_pressure'] = SwipeEvent.get_distance_start_min_pressure(\n",
    "            self.df)\n",
    "\n",
    "        # Time Features\n",
    "        feature_values['hold_time'] = SwipeEvent.get_hold_time(self.df)\n",
    "        feature_values['time_to_max_pressure'] = SwipeEvent.get_time_to_max_pressure(\n",
    "            self.df)\n",
    "        feature_values['time_to_min_pressure'] = SwipeEvent.get_time_to_min_pressure(\n",
    "            self.df)\n",
    "\n",
    "        # Product Features\n",
    "        feature_values['product_max_size_and_max_pressure'] = SwipeEvent.get_product_max_size_max_pressure(\n",
    "            self.df)\n",
    "        feature_values['product_max_size_and_hold_time'] = SwipeEvent.get_product_max_size_hold_time(\n",
    "            self.df)\n",
    "        feature_values['product_min_size_and_hold_time'] = SwipeEvent.get_product_min_size_hold_time(\n",
    "            self.df)\n",
    "        feature_values['product_avg_size_and_hold_time'] = SwipeEvent.get_product_avg_size_hold_time(\n",
    "            self.df)\n",
    "\n",
    "        # Slope Features\n",
    "        feature_values['slope_start_to_end'] = SwipeEvent.get_slope_start_end(\n",
    "            self.df)\n",
    "        feature_values['slope_start_to_median'] = SwipeEvent.get_slope_start_median(\n",
    "            self.df)\n",
    "        feature_values['slope_median_to_end'] = SwipeEvent.get_slope_median_end(\n",
    "            self.df)\n",
    "        feature_values['difference_in_slope_start_to_median_and_median_to_end'] = SwipeEvent.get_difference_in_slope_start_median_end(\n",
    "            self.df)\n",
    "\n",
    "        return feature_values\n",
    "\n",
    "    # Parent DataFrames\n",
    "    def get_orientation(df):\n",
    "        return df['orientation'].iloc[0]\n",
    "\n",
    "    def get_event_no(df):\n",
    "        return df['event_no'].iloc[0]\n",
    "\n",
    "    def get_session_id(df):\n",
    "        return df['session_id'].iloc[0]\n",
    "\n",
    "    def get_user_id(df):\n",
    "        return df['user_id'].iloc[0]\n",
    "\n",
    "    def get_device_type(df):\n",
    "        return df['device_type'].iloc[0]\n",
    "\n",
    "    def get_age(df):\n",
    "        return df['age'].iloc[0]\n",
    "\n",
    "    def get_age_group(df):\n",
    "        return df['age_group'].iloc[0]\n",
    "\n",
    "    # Direction\n",
    "    def get_direction(df):\n",
    "        orientation = df['orientation'].iloc[0]\n",
    "        direction = 'unknown'\n",
    "        if orientation == 'horizontal':\n",
    "            if df['x'].iloc[0] < df['x'].iloc[-1]:\n",
    "                direction = 'swipe-right'\n",
    "            else:\n",
    "                direction = 'swipe-left'\n",
    "        elif orientation == 'vertical':\n",
    "            if df['y'].iloc[0] < df['y'].iloc[-1]:\n",
    "                direction = 'swipe-up'\n",
    "            else:\n",
    "                direction = 'swipe-down'\n",
    "        return direction\n",
    "\n",
    "    # Velocity Features\n",
    "    def get_first_non_zero_velocity_main_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_first_non_zero_vx(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_first_non_zero_vy(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_first_non_zero_vx(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_first_non_zero_vy(df) * (-1)\n",
    "\n",
    "    def get_first_non_zero_velocity_cross_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_first_non_zero_vy(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_first_non_zero_vx(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_first_non_zero_vy(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_first_non_zero_vx(df) * (-1)\n",
    "\n",
    "    def get_last_non_zero_velocity_main_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_last_non_zero_vx(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_last_non_zero_vy(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_last_non_zero_vx(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_last_non_zero_vy(df) * (-1)\n",
    "\n",
    "    def get_last_non_zero_velocity_cross_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_last_non_zero_vy(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_last_non_zero_vx(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_last_non_zero_vy(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_last_non_zero_vx(df) * (-1)\n",
    "\n",
    "    def get_start_velocity_main_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_start_vx(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_start_vy(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_start_vx(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_start_vy(df) * (-1)\n",
    "\n",
    "    def get_start_velocity_cross_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_start_vy(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_start_vx(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_start_vy(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_start_vx(df) * (-1)\n",
    "\n",
    "    def get_end_velocity_main_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_end_vx(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_end_vy(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_end_vx(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_end_vy(df) * (-1)\n",
    "\n",
    "    def get_end_velocity_cross_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_end_vy(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_end_vx(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_end_vy(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_end_vx(df) * (-1)\n",
    "\n",
    "    def get_min_velocity_main_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_min_vx(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_min_vy(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_min_vx(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_min_vy(df) * (-1)\n",
    "\n",
    "    def get_min_velocity_cross_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_min_vy(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_min_vx(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_min_vy(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_min_vx(df) * (-1)\n",
    "\n",
    "    def get_max_velocity_main_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_max_vx(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_max_vy(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_max_vx(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_max_vy(df) * (-1)\n",
    "\n",
    "    def get_max_velocity_cross_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_max_vy(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_max_vx(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_max_vy(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_max_vx(df) * (-1)\n",
    "\n",
    "    def get_avg_velocity_main_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_avg_vx(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_avg_vy(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_avg_vx(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_avg_vy(df) * (-1)\n",
    "\n",
    "    def get_avg_velocity_cross_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_avg_vy(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_avg_vx(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_avg_vy(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_avg_vx(df) * (-1)\n",
    "\n",
    "    def get_range_in_velocity_main_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_range_in_vx(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_range_in_vy(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_range_in_vx(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_range_in_vy(df) * (-1)\n",
    "\n",
    "    def get_range_in_velocity_cross_axis(df):\n",
    "        direction = SwipeEvent.get_direction(df)\n",
    "        if direction == 'swipe-right':\n",
    "            return SwipeEvent.get_range_in_vy(df)\n",
    "        elif direction == 'swipe-up':\n",
    "            return SwipeEvent.get_range_in_vx(df)\n",
    "        elif direction == 'swipe-left':\n",
    "            return SwipeEvent.get_range_in_vy(df) * (-1)\n",
    "        elif direction == 'swipe-down':\n",
    "            return SwipeEvent.get_range_in_vx(df) * (-1)\n",
    "\n",
    "    def get_start_vx(df):\n",
    "        return df['vx'].iloc[0]\n",
    "\n",
    "    def get_start_vy(df):\n",
    "        return df['vy'].iloc[0]\n",
    "\n",
    "    def get_end_vx(df):\n",
    "        return df['vx'].iloc[-1]\n",
    "\n",
    "    def get_end_vy(df):\n",
    "        return df['vy'].iloc[-1]\n",
    "\n",
    "    def get_first_non_zero_vx(df):\n",
    "        non_zero_vx_series = df[(df['vx'] != 0) & (~df['vx'].isna())]['vx']\n",
    "        if non_zero_vx_series.empty:\n",
    "            return 0\n",
    "        first_non_zero_index = non_zero_vx_series.idxmin()\n",
    "        first_non_zero_value = df.at[first_non_zero_index, 'vx']\n",
    "        return first_non_zero_value\n",
    "\n",
    "    def get_first_non_zero_vy(df):\n",
    "        non_zero_vy_series = df[(df['vy'] != 0) & (~df['vy'].isna())]['vy']\n",
    "        if non_zero_vy_series.empty:\n",
    "            return 0\n",
    "        first_non_zero_index = non_zero_vy_series.idxmin()\n",
    "        first_non_zero_value = df.at[first_non_zero_index, 'vy']\n",
    "        return first_non_zero_value\n",
    "\n",
    "    def get_last_non_zero_vx(df):\n",
    "        non_zero_vx_series = df[(df['vx'] != 0) & (~df['vx'].isna())]['vx']\n",
    "        if non_zero_vx_series.empty:\n",
    "            return 0\n",
    "        last_non_zero_index = non_zero_vx_series.idxmax()\n",
    "        last_non_zero_value = df.at[last_non_zero_index, 'vx']\n",
    "        return last_non_zero_value\n",
    "\n",
    "    def get_last_non_zero_vy(df):\n",
    "        non_zero_vy_series = df[(df['vy'] != 0) & (~df['vy'].isna())]['vy']\n",
    "        if non_zero_vy_series.empty:\n",
    "            return 0\n",
    "        last_non_zero_index = non_zero_vy_series.idxmax()\n",
    "        last_non_zero_value = df.at[last_non_zero_index, 'vy']\n",
    "        return last_non_zero_value\n",
    "\n",
    "    def get_min_vx(df):\n",
    "        return df['vx'].min()\n",
    "\n",
    "    def get_min_vy(df):\n",
    "        return df['vy'].min()\n",
    "\n",
    "    def get_max_vx(df):\n",
    "        return df['vx'].max()\n",
    "\n",
    "    def get_max_vy(df):\n",
    "        return df['vy'].max()\n",
    "\n",
    "    def get_avg_vx(df):\n",
    "        return df['vx'].mean()\n",
    "\n",
    "    def get_avg_vy(df):\n",
    "        return df['vy'].mean()\n",
    "\n",
    "    def get_range_in_vx(df):\n",
    "        return SwipeEvent.get_max_vx(df) - SwipeEvent.get_min_vx(df)\n",
    "\n",
    "    def get_range_in_vy(df):\n",
    "        return SwipeEvent.get_max_vy(df) - SwipeEvent.get_min_vy(df)\n",
    "\n",
    "    # Product Features\n",
    "    def get_product_max_size_max_pressure(df):\n",
    "        max_size = SwipeEvent.get_max_size(df)\n",
    "        max_pressure = SwipeEvent.get_max_pressure(df)\n",
    "        return max_size * max_pressure\n",
    "\n",
    "    def get_product_avg_size_hold_time(df):\n",
    "        avg_size = SwipeEvent.get_avg_size(df)\n",
    "        total_duration = SwipeEvent.get_hold_time(df)\n",
    "        return avg_size * total_duration\n",
    "\n",
    "    def get_product_max_size_hold_time(df):\n",
    "        max_size = SwipeEvent.get_max_size(df)\n",
    "        total_duration = SwipeEvent.get_hold_time(df)\n",
    "        return max_size * total_duration\n",
    "\n",
    "    def get_product_min_size_hold_time(df):\n",
    "        min_size = SwipeEvent.get_min_size(df)\n",
    "        total_duration = SwipeEvent.get_hold_time(df)\n",
    "        return min_size * total_duration\n",
    "\n",
    "    # Distance Features\n",
    "    def get_total_distance(df):\n",
    "        x1, y1 = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        x2, y2 = df['x'].iloc[-1], df['y'].iloc[-1]\n",
    "        distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        return distance\n",
    "\n",
    "    def get_distance_start_max_pressure(df):\n",
    "        start_x, start_y = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        max_pressure_index = df['pressure'].idxmax()\n",
    "        max_pressure_x = df['x'].iloc[max_pressure_index]\n",
    "        max_pressure_y = df['y'].iloc[max_pressure_index]\n",
    "        distance = math.sqrt((max_pressure_x - start_x) **\n",
    "                             2 + (max_pressure_y - start_y)**2)\n",
    "        return distance\n",
    "\n",
    "    def get_distance_start_min_pressure(df):\n",
    "        start_x, start_y = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        min_pressure_index = df['pressure'].idxmin()\n",
    "        min_pressure_x = df['x'].iloc[min_pressure_index]\n",
    "        min_pressure_y = df['y'].iloc[min_pressure_index]\n",
    "        distance = math.sqrt((min_pressure_x - start_x) **\n",
    "                             2 + (min_pressure_y - start_y)**2)\n",
    "        return distance\n",
    "\n",
    "    # Size Features\n",
    "    def get_start_size(df):\n",
    "        return df['size'].iloc[0]\n",
    "\n",
    "    def get_end_size(df):\n",
    "        return df['size'].iloc[-1]\n",
    "\n",
    "    def get_max_size(df):\n",
    "        return df['size'].max()\n",
    "\n",
    "    def get_min_size(df):\n",
    "        return df['size'].min()\n",
    "\n",
    "    def get_avg_size(df):\n",
    "        return df['size'].mean()\n",
    "\n",
    "    def get_range_in_size(df):\n",
    "        return SwipeEvent.get_max_size(df) - SwipeEvent.get_min_size(df)\n",
    "\n",
    "    # Pressure Features\n",
    "    def get_start_pressure(df):\n",
    "        return df['pressure'].iloc[0]\n",
    "\n",
    "    def get_end_pressure(df):\n",
    "        return df['pressure'].iloc[-1]\n",
    "\n",
    "    def get_max_pressure(df):\n",
    "        return df['pressure'].max()\n",
    "\n",
    "    def get_min_pressure(df):\n",
    "        return df['pressure'].min()\n",
    "\n",
    "    def get_avg_pressure(df):\n",
    "        return df['pressure'].mean()\n",
    "\n",
    "    def get_range_in_pressure(df):\n",
    "        return SwipeEvent.get_max_pressure(df) - SwipeEvent.get_min_pressure(df)\n",
    "\n",
    "    # Slope Features\n",
    "    def get_slope_start_end(df):\n",
    "        x1, y1 = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        x2, y2 = df['x'].iloc[-1], df['y'].iloc[-1]\n",
    "        if x2 - x1 != 0:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "        else:\n",
    "            slope = 0  # vertical slope is undefined\n",
    "        return slope\n",
    "\n",
    "    def get_slope_start_median(df):\n",
    "        x1, y1 = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        median_index = len(df) // 2\n",
    "        x_median = df['x'].iloc[median_index]\n",
    "        y_median = df['y'].iloc[median_index]\n",
    "        if x_median - x1 != 0:\n",
    "            slope = (y_median - y1) / (x_median - x1)\n",
    "        else:\n",
    "            slope = 0  # vertical slope is undefined\n",
    "        return slope\n",
    "\n",
    "    def get_slope_median_end(df):\n",
    "        median_index = len(df) // 2\n",
    "        x_median = df['x'].iloc[median_index]\n",
    "        y_median = df['y'].iloc[median_index]\n",
    "        x_end = df['x'].iloc[-1]\n",
    "        y_end = df['y'].iloc[-1]\n",
    "        if x_end - x_median != 0:\n",
    "            slope = (y_end - y_median) / (x_end - x_median)\n",
    "        else:\n",
    "            slope = 0  # vertical slope is undefined\n",
    "        return slope\n",
    "\n",
    "    def get_difference_in_slope_start_median_end(df):\n",
    "        return abs(SwipeEvent.get_slope_start_median(df) - SwipeEvent.get_slope_median_end(df))\n",
    "\n",
    "    # Duration Features\n",
    "    def get_time_to_max_pressure(df):\n",
    "        max_pressure_index = df['pressure'].idxmax()\n",
    "        time_to_max_pressure = df['mille'].iloc[max_pressure_index] - \\\n",
    "            df['mille'].iloc[0]\n",
    "        return time_to_max_pressure\n",
    "\n",
    "    def get_time_to_min_pressure(df):\n",
    "        min_pressure_index = df['pressure'].idxmin()\n",
    "        time_to_min_pressure = df['mille'].iloc[min_pressure_index] - \\\n",
    "            df['mille'].iloc[0]\n",
    "        return time_to_min_pressure\n",
    "\n",
    "    def get_hold_time(df):\n",
    "        total_duration = df['mille'].iloc[-1] - df['mille'].iloc[0]\n",
    "        return total_duration\n",
    "\n",
    "    def get_speed(df):\n",
    "        x1, y1 = df['x'].iloc[0], df['y'].iloc[0]\n",
    "        x2, y2 = df['x'].iloc[-1], df['y'].iloc[-1]\n",
    "        total_distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        total_duration = df['mille'].iloc[-1] - df['mille'].iloc[0]\n",
    "        speed = total_distance / total_duration\n",
    "        return speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swipe_features_df():\n",
    "\n",
    "    # attempt to load dataframe from checkpoint\n",
    "    swipe_features_df = load_dataframe(\"swipe_features_df\")\n",
    "\n",
    "    # if checkpoint does not exist, create and save dataframe\n",
    "    if (swipe_features_df is None):\n",
    "        swipe_features_df = build_swipe_features_df()\n",
    "        save_dataframe(swipe_features_df)\n",
    "\n",
    "    return swipe_features_df\n",
    "\n",
    "\n",
    "def build_swipe_features_df():\n",
    "\n",
    "    print(\"Building swipe_features_df...\")\n",
    "\n",
    "    # list of swipe feature dfs, one for each event, to be concatenated at the end\n",
    "    swipe_feature_dfs = list()\n",
    "\n",
    "    # Get swipe_df\n",
    "    swipe_df = get_swipe_df()\n",
    "\n",
    "    # Get swipe events\n",
    "    events = swipe_df['event_no'].unique()\n",
    "\n",
    "    # For each event get features dataframe and append to list\n",
    "    for event in events:\n",
    "        swipe_event_df = swipe_df[swipe_df['event_no'] == event]\n",
    "        swipe_event_df = SwipeEvent(swipe_event_df).get_feature_dataframe()\n",
    "        swipe_feature_dfs.append(swipe_event_df)\n",
    "\n",
    "    # concatenate all swipe features into a single dataframe\n",
    "    swipe_features_df = pd.concat(swipe_feature_dfs)\n",
    "\n",
    "    # Replace Not a Number (NaN) with zero\n",
    "    swipe_features_df = swipe_features_df.fillna(0)\n",
    "\n",
    "    # Replace infinite values with 0\n",
    "    swipe_features_df = swipe_features_df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # Reset Indexes\n",
    "    swipe_features_df = swipe_features_df.reset_index()\n",
    "\n",
    "    # Remove redundant Index column\n",
    "    swipe_features_df = swipe_features_df.drop(columns=['index'])\n",
    "\n",
    "    return swipe_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_swipe_features_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Users for Training and Testing\n",
    "\n",
    "Split users into phone and tablet user groups, then split phone and tablet user groups into training and testing groups where no user appears in both training and testing sets. Users will be split by age where about 80% of users will be used for training and 20% will be used for testing.\n",
    "\n",
    "**Note:** by splitting users into training and testing groups we ensure bias is not introduced into any Machine Learning model because the same user's gestures do not appear in both training and testing datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define method to split data where no user appears in both training and testing\n",
    "# uses group shuffle split\n",
    "# protects models from developing a bias toward any user's samples\n",
    "def train_test_split_on_users(df):\n",
    "    test_size = 0.2\n",
    "    n_splits = 1\n",
    "    groups = df['user_id']\n",
    "\n",
    "    # Define Group Shuffle Split\n",
    "    gss = GroupShuffleSplit(\n",
    "        test_size=test_size,\n",
    "        n_splits=n_splits,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Split users for training and testing\n",
    "    # So no user appears in both sets\n",
    "    train_indices, test_indices = next(gss.split(df, groups=groups))\n",
    "\n",
    "    X_train = df.iloc[train_indices]\n",
    "    X_test = df.iloc[test_indices]\n",
    "    y_train = X_train['age_group']\n",
    "    y_test = X_test['age_group']\n",
    "\n",
    "    # define groups for TPOT\n",
    "    groups = X_train['user_id']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, groups\n",
    "\n",
    "\n",
    "def remove_columns(df):\n",
    "    # Columns to drop if present\n",
    "    columns_to_drop = ['gesture', 'user_id', 'session_id', 'device_type',\n",
    "                       'event_no', 'age', 'age_group', 'direction', 'orientation', 'tapped']\n",
    "\n",
    "    # Drop columns if they exist in the dataframe\n",
    "    df = df.drop(columns=[col for col in df.columns if any(\n",
    "        substring in col for substring in columns_to_drop)])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def verify_users(X_train, X_test):\n",
    "    print(\"Verifying successful split...\")\n",
    "    common_user_ids = set(X_train['user_id']).intersection(\n",
    "        set(X_test['user_id']))\n",
    "    if len(common_user_ids) == 0:\n",
    "        print(\"No user_id is present in both training and testing.\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"The following user_ids are present in both training and testing: {common_user_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test_user_split(X_train, X_test):\n",
    "    # Get Users\n",
    "    X_train_users = X_train.drop_duplicates(subset=['user_id'], keep='first')\n",
    "    X_test_users = X_test.drop_duplicates(subset=['user_id'], keep='first')\n",
    "\n",
    "    # Plotting histograms\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Training data\n",
    "    plt.subplot(1, 2, 1)\n",
    "    train_counts = X_train_users['age_group'].value_counts().reindex(\n",
    "        ['child', 'teen', 'adult'])\n",
    "    train_counts.plot(kind='bar', edgecolor='black')\n",
    "    plt.title('Age Group Distribution of Users\\nin Training Data')\n",
    "    plt.xlabel('Age Group')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Adding count labels above each bar in training data\n",
    "    for idx, count in enumerate(train_counts):\n",
    "        plt.text(idx, count, str(int(count)), ha='center', va='bottom')\n",
    "\n",
    "    # Testing data\n",
    "    plt.subplot(1, 2, 2)\n",
    "    test_counts = X_test_users['age_group'].value_counts().reindex(\n",
    "        ['child', 'teen', 'adult'])\n",
    "    test_counts.plot(kind='bar', edgecolor='black')\n",
    "    plt.title('Age Group Distribution of Users\\nin Testing Data')\n",
    "    plt.xlabel('Age Group')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Adding count labels above each bar in testing data\n",
    "    for idx, count in enumerate(test_counts):\n",
    "        plt.text(idx, count, str(int(count)), ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_train_test_sample_split(X_train, X_test):\n",
    "    # Plotting histograms\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Training data\n",
    "    plt.subplot(1, 2, 1)\n",
    "    train_counts = X_train['age_group'].value_counts().reindex(\n",
    "        ['child', 'teen', 'adult'])\n",
    "    train_counts.plot(kind='bar', edgecolor='black')\n",
    "    plt.title('Age Group Distribution of Samples\\nin Training Data')\n",
    "    plt.xlabel('Age Group')\n",
    "    plt.ylabel('Number of Samples')\n",
    "\n",
    "    # Adding count labels above each bar in training data\n",
    "    for idx, count in enumerate(train_counts):\n",
    "        plt.text(idx, count, str(int(count)), ha='center', va='bottom')\n",
    "\n",
    "    # Testing data\n",
    "    plt.subplot(1, 2, 2)\n",
    "    test_counts = X_test['age_group'].value_counts().reindex(\n",
    "        ['child', 'teen', 'adult'])\n",
    "    test_counts.plot(kind='bar', edgecolor='black')\n",
    "    plt.title('Age Group Distribution of Samples\\nin Testing Data')\n",
    "    plt.xlabel('Age Group')\n",
    "    plt.ylabel('Number of Samples')\n",
    "\n",
    "    # Adding count labels above each bar in testing data\n",
    "    for idx, count in enumerate(test_counts):\n",
    "        plt.text(idx, count, str(int(count)), ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def report_train_test_user_split(X_train, X_test):\n",
    "    # get users\n",
    "    X_train_users = X_train.drop_duplicates(subset=['user_id'], keep='first')\n",
    "    X_test_users = X_test.drop_duplicates(subset=['user_id'], keep='first')\n",
    "\n",
    "    # Report average split by user group (ie. 80/20)\n",
    "    num_child_train = len(X_train_users[X_train_users['age_group'] == 'child'])\n",
    "    num_child_test = len(X_test_users[X_test_users['age_group'] == 'child'])\n",
    "    total_num_child = num_child_train + num_child_test\n",
    "    num_teen_train = len(X_train_users[X_train_users['age_group'] == 'teen'])\n",
    "    num_teen_test = len(X_test_users[X_test_users['age_group'] == 'teen'])\n",
    "    total_num_teen = num_teen_train + num_teen_test\n",
    "    num_adult_train = len(X_train_users[X_train_users['age_group'] == 'adult'])\n",
    "    num_adult_test = len(X_test_users[X_test_users['age_group'] == 'adult'])\n",
    "    total_num_adult = num_adult_train + num_adult_test\n",
    "\n",
    "    percent_child_train = round(num_child_train/total_num_child*100)\n",
    "    percent_child_test = round(num_child_test/total_num_child*100)\n",
    "    percent_teen_train = round(num_teen_train/total_num_teen*100)\n",
    "    percent_teen_test = round(num_teen_test/total_num_teen*100)\n",
    "    percent_adult_train = round(num_adult_train/total_num_adult*100)\n",
    "    percent_adult_test = round(num_adult_test/total_num_adult*100)\n",
    "\n",
    "    average_train = round(\n",
    "        (percent_child_train + percent_teen_train + percent_adult_train)/3)\n",
    "    average_test = round(\n",
    "        (percent_child_test + percent_teen_test + percent_adult_test)/3)\n",
    "\n",
    "    print(f\"Child User Split: {percent_child_train}/{percent_child_test}\")\n",
    "    print(f\" Teen User Split: {percent_teen_train}/{percent_teen_test}\")\n",
    "    print(f\"Adult User Split: {percent_adult_train}/{percent_adult_test}\")\n",
    "    print(\"------------------------\")\n",
    "    print(f\"   Average Split: {average_train}/{average_test}\")\n",
    "\n",
    "\n",
    "def report_train_test_sample_split(X_train, X_test):\n",
    "\n",
    "    # Report average split by user group (ie. 80/20)\n",
    "    num_child_train = len(X_train[X_train['age_group'] == 'child'])\n",
    "    num_child_test = len(X_test[X_test['age_group'] == 'child'])\n",
    "    total_num_child = num_child_train + num_child_test\n",
    "    num_teen_train = len(X_train[X_train['age_group'] == 'teen'])\n",
    "    num_teen_test = len(X_test[X_test['age_group'] == 'teen'])\n",
    "    total_num_teen = num_teen_train + num_teen_test\n",
    "    num_adult_train = len(X_train[X_train['age_group'] == 'adult'])\n",
    "    num_adult_test = len(X_test[X_test['age_group'] == 'adult'])\n",
    "    total_num_adult = num_adult_train + num_adult_test\n",
    "\n",
    "    percent_child_train = round(num_child_train/total_num_child*100)\n",
    "    percent_child_test = round(num_child_test/total_num_child*100)\n",
    "    percent_teen_train = round(num_teen_train/total_num_teen*100)\n",
    "    percent_teen_test = round(num_teen_test/total_num_teen*100)\n",
    "    percent_adult_train = round(num_adult_train/total_num_adult*100)\n",
    "    percent_adult_test = round(num_adult_test/total_num_adult*100)\n",
    "\n",
    "    average_train = round(\n",
    "        (percent_child_train + percent_teen_train + percent_adult_train)/3)\n",
    "    average_test = round(\n",
    "        (percent_child_test + percent_teen_test + percent_adult_test)/3)\n",
    "\n",
    "    print(f\"Child Sample Split: {percent_child_train}/{percent_child_test}\")\n",
    "    print(f\" Teen Sample Split: {percent_teen_train}/{percent_teen_test}\")\n",
    "    print(f\"Adult Sample Split: {percent_adult_train}/{percent_adult_test}\")\n",
    "    print(\"------------------------\")\n",
    "    print(f\"   Average Split: {average_train}/{average_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Gesture Classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Helper Methods\n",
    "\n",
    "\n",
    "def get_features_df(gesture, device_type=None, direction=None):\n",
    "    print(f\"Getting {gesture} features dataframe...\")\n",
    "    if gesture not in ['tap', 'zoom', 'swipe']:\n",
    "        assert ValueError(\"gesture must be one of 'tap', 'zoom' or 'swipe'\")\n",
    "    if device_type and device_type not in ['phone', 'tablet']:\n",
    "        assert ValueError(\"device_type must be one of 'phone', or 'tablet'\")\n",
    "    if direction and direction not in ['zoom-in', 'zoom-out', 'swipe-up', 'swipe-down', 'swipe-left', 'swipe-right']:\n",
    "        assert ValueError(\n",
    "            \"direction must be one of 'zoom-in', 'zoom-out', 'swipe-up', 'swipe-down', 'swipe-left', 'swipe-right'\")\n",
    "\n",
    "    # get feature_df\n",
    "    feature_df = None\n",
    "    if 'tap' == gesture:\n",
    "        feature_df = get_tap_features_df()\n",
    "    elif 'zoom' == gesture:\n",
    "        feature_df = get_zoom_features_df()\n",
    "    elif 'swipe' == gesture:\n",
    "        feature_df = get_swipe_features_df()\n",
    "\n",
    "    # filter on device_type\n",
    "    if device_type:\n",
    "        feature_df = feature_df[feature_df['device_type'] == device_type]\n",
    "\n",
    "    # filter on direction\n",
    "    if direction:\n",
    "        feature_df = feature_df[feature_df['direction'] == direction]\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "\n",
    "def find_best_model_with_tpot(X_train, y_train, groups=None, generations=None, population_size=None):\n",
    "    # define group shuffle split\n",
    "    gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "\n",
    "    # scoring (F1 Score: Which average should we choose?)\n",
    "    # \"In the context of an imbalanced dataset where equal importance is attributed to all classes, opting for the macro average stands as a sound choice since it treats each class with equal significance.\"\n",
    "    # https://iamirmasoud.com/2022/06/19/understanding-micro-macro-and-weighted-averages-for-scikit-learn-metrics-in-multi-class-classification-with-example/\n",
    "    scoring = 'f1_macro'\n",
    "\n",
    "    # set generations\n",
    "    if not generations:\n",
    "        generations = 100 # default\n",
    "    \n",
    "    # set population_size\n",
    "    if not population_size:\n",
    "        population_size = 100 # default\n",
    "\n",
    "    # initialize model\n",
    "    model = TPOTClassifier(\n",
    "        generations=generations,\n",
    "        population_size=population_size,\n",
    "        cv=gss,\n",
    "        scoring=scoring,\n",
    "        verbosity=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # perform Tree-based Pipeline Optimization\n",
    "    if groups is not None:\n",
    "        model.fit(X_train, y_train, groups=groups)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def export_model(model, device_type, first_gesture, second_gesture=None, first_gesture_direction=None, second_gesture_direction=None):\n",
    "    # Create the TPOT directory if it doesn't exist\n",
    "    tpot_dir = 'TPOT'\n",
    "    if not os.path.exists(tpot_dir):\n",
    "        os.makedirs(tpot_dir)\n",
    "\n",
    "    # if first gesture has a direction then use it\n",
    "    if first_gesture_direction:\n",
    "        first_gesture = first_gesture_direction.replace('-', '_')\n",
    "\n",
    "    if second_gesture:\n",
    "        # Create subfolder if it does not exist\n",
    "        subfolder = os.path.join(tpot_dir, 'multimodal')\n",
    "        if not os.path.exists(subfolder):\n",
    "            os.makedirs(subfolder)\n",
    "\n",
    "        # if second gesture has a direction then use it\n",
    "        if second_gesture_direction:\n",
    "            second_gesture = second_gesture_direction.replace('-', '_')\n",
    "\n",
    "        # create phone or tablet folder\n",
    "        if not os.path.exists(os.path.join(subfolder, device_type)):\n",
    "            os.makedirs(os.path.join(subfolder, device_type))\n",
    "\n",
    "        # export model\n",
    "        model.export(\n",
    "            f'{subfolder}/{device_type}/{first_gesture}_and_{second_gesture}_best_model.py')\n",
    "\n",
    "    else:\n",
    "        # Create subfolder if it does not exist\n",
    "        subfolder = os.path.join(tpot_dir, 'unimodal')\n",
    "        if not os.path.exists(subfolder):\n",
    "            os.makedirs(subfolder)\n",
    "\n",
    "        # create phone or tablet folder\n",
    "        if not os.path.exists(os.path.join(subfolder, device_type)):\n",
    "            os.makedirs(os.path.join(subfolder, device_type))\n",
    "\n",
    "        # export model\n",
    "        model.export(\n",
    "            f'{subfolder}/{device_type}/{first_gesture}_best_model.py')\n",
    "\n",
    "\n",
    "def exported_model_exists(device_type, first_gesture, second_gesture=None, first_gesture_direction=None, second_gesture_direction=None):\n",
    "    # Sample output directories:\n",
    "    # /TPOT/unimodal/phone/tap_best_model.py\n",
    "    # /TPOT/unimodal/phone/swipe_right_best_model.py\n",
    "    # /TPOT/unimodal/tablet/zoom_in_best_model.py\n",
    "    # /TPOT/multimodal/tablet/tap_and_swipe_right_best_model.py\n",
    "\n",
    "    if first_gesture_direction:\n",
    "        first_gesture = first_gesture_direction.replace('-', '_')\n",
    "    if second_gesture_direction:\n",
    "        second_gesture = second_gesture_direction.replace('-', '_')\n",
    "\n",
    "    if second_gesture:\n",
    "        if os.path.exists(f'TPOT/multimodal/{device_type}/{first_gesture}_and_{second_gesture}_best_model.py'):\n",
    "            return True\n",
    "    else:\n",
    "        if os.path.exists(f'TPOT/unimodal/{device_type}/{first_gesture}_best_model.py'):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def show_accuracy(y_test, y_pred):\n",
    "    print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "\n",
    "def show_confusion_matrix(y_test, y_pred):\n",
    "    # create confusion matrix\n",
    "    classes = ['child', 'teen', 'adult']\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    # visualize using Seaborn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_classification_report(y_test, y_pred):\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'tap'\n",
    "device_type = 'phone'\n",
    "direction = None\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type, first_gesture=gesture)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tpot.builtins import ZeroCount\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_tap_phone_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.5289661957396079\n",
    "    exported_pipeline = make_pipeline(\n",
    "        SelectPercentile(score_func=f_classif, percentile=23),\n",
    "        RobustScaler(),\n",
    "        ZeroCount(),\n",
    "        MLPClassifier(alpha=0.1, learning_rate_init=0.001)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This optimal model, `get_tap_phone_best_model()` is a pipeline discovered by the Tree-based Pipeline Optimization Tool (TPOT)\n",
    "It was trained using input samples grouped by user_id\n",
    "The selected scoring method is macro F1 score and achieved an average accuracy of 84% with imbalanced guesses for only child and adult (no teen guesses)\n",
    "Training ended after 100 generations after resolving an error that occurs when providing sample weights to TPOTClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_tap_phone_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tablet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'tap'\n",
    "device_type = 'tablet'\n",
    "direction = None\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type, first_gesture=gesture)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model (from TPOT export)\n",
    "from sklearn.feature_selection import SelectFwe, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator, ZeroCount\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def get_tap_tablet_best_model_f1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.7674201152370437\n",
    "    exported_pipeline = make_pipeline(\n",
    "        make_union(\n",
    "            make_pipeline(\n",
    "                ZeroCount(),\n",
    "                SelectFwe(score_func=f_classif, alpha=0.04)\n",
    "            ),\n",
    "            FunctionTransformer(copy)\n",
    "        ),\n",
    "        MLPClassifier(alpha=0.1, learning_rate_init=0.001)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model (from TPOT export)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_tap_tablet_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.6706390167060482\n",
    "    exported_pipeline = make_pipeline(\n",
    "        VarianceThreshold(threshold=0.001),\n",
    "        StandardScaler(),\n",
    "        SGDClassifier(alpha=0.001, eta0=0.01, fit_intercept=False, l1_ratio=1.0,\n",
    "                      learning_rate=\"constant\", loss=\"hinge\", penalty=\"elasticnet\", power_t=0.1)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_tap_tablet_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zoom-In\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'zoom'\n",
    "device_type = 'phone'\n",
    "direction = 'zoom-in'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "def get_zoom_in_phone_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.6212860013655245\n",
    "    exported_pipeline = SGDClassifier(\n",
    "        alpha=0.001,\n",
    "        eta0=0.1,\n",
    "        fit_intercept=True,\n",
    "        l1_ratio=0.25,\n",
    "        learning_rate=\"constant\",\n",
    "        loss=\"squared_hinge\",\n",
    "        penalty=\"elasticnet\",\n",
    "        power_t=100.0\n",
    "    )\n",
    "    # Fix random state in exported estimator\n",
    "    if hasattr(exported_pipeline, 'random_state'):\n",
    "        setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_zoom_in_phone_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zoom-Out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'zoom'\n",
    "device_type = 'phone'\n",
    "direction = 'zoom-out'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "def get_zoom_out_phone_best_model_f1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.9099837803261337\n",
    "    exported_pipeline = SGDClassifier(\n",
    "        alpha=0.001,\n",
    "        eta0=0.01,\n",
    "        fit_intercept=False,\n",
    "        l1_ratio=0.0,\n",
    "        learning_rate=\"invscaling\",\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"elasticnet\",\n",
    "        power_t=0.0\n",
    "    )\n",
    "    # Fix random state in exported estimator\n",
    "    if hasattr(exported_pipeline, 'random_state'):\n",
    "        setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "def get_zoom_out_phone_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.5976135115260606\n",
    "    exported_pipeline = SGDClassifier(\n",
    "        alpha=0.001,\n",
    "        eta0=0.01,\n",
    "        fit_intercept=False,\n",
    "        l1_ratio=0.0,\n",
    "        learning_rate=\"constant\",\n",
    "        loss=\"hinge\",\n",
    "        penalty=\"elasticnet\",\n",
    "        power_t=0.5\n",
    "    )\n",
    "    # Fix random state in exported estimator\n",
    "    if hasattr(exported_pipeline, 'random_state'):\n",
    "        setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_zoom_out_phone_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tablet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zoom-In\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'zoom'\n",
    "device_type = 'tablet'\n",
    "direction = 'zoom-in'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_zoom_in_tablet_best_model_f1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.8304841137632715\n",
    "    exported_pipeline = make_pipeline(\n",
    "        MinMaxScaler(),\n",
    "        RFE(\n",
    "            estimator=ExtraTreesClassifier(\n",
    "                criterion=\"gini\",\n",
    "                max_features=0.9500000000000001,\n",
    "                n_estimators=100\n",
    "            ),\n",
    "            step=0.9000000000000001\n",
    "        ),\n",
    "        FastICA(tol=0.5),\n",
    "        StandardScaler(),\n",
    "        MLPClassifier(alpha=0.01, learning_rate_init=0.01)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tpot.builtins import ZeroCount\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_zoom_in_tablet_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.5718205866673142\n",
    "    exported_pipeline = make_pipeline(\n",
    "        MinMaxScaler(),\n",
    "        FastICA(tol=0.9500000000000001),\n",
    "        ZeroCount(),\n",
    "        MLPClassifier(alpha=0.001, learning_rate_init=0.01)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_zoom_in_tablet_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zoom-Out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'zoom'\n",
    "device_type = 'tablet'\n",
    "direction = 'zoom-out'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_zoom_out_tablet_best_model_f1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.8328819025830071\n",
    "    exported_pipeline = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        MaxAbsScaler(),\n",
    "        RFE(\n",
    "            estimator=ExtraTreesClassifier(\n",
    "                criterion=\"gini\",\n",
    "                max_features=0.15000000000000002,\n",
    "                n_estimators=100\n",
    "            ),\n",
    "            step=0.4\n",
    "        ),\n",
    "        MLPClassifier(alpha=0.01, learning_rate_init=0.001)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_zoom_out_tablet_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.5154457915481714\n",
    "    exported_pipeline = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SelectPercentile(score_func=f_classif, percentile=58),\n",
    "        MLPClassifier(alpha=0.0001, learning_rate_init=0.01)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_zoom_out_tablet_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swipe-Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'swipe'\n",
    "device_type = 'phone'\n",
    "direction = 'swipe-up'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_up_phone_best_model_f1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.7512237035406689\n",
    "    exported_pipeline = make_pipeline(\n",
    "        RobustScaler(),\n",
    "        RandomForestClassifier(\n",
    "            bootstrap=True,\n",
    "            criterion=\"gini\",\n",
    "            max_features=0.8500000000000001,\n",
    "            min_samples_leaf=17,\n",
    "            min_samples_split=12,\n",
    "            n_estimators=100\n",
    "        )\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, RobustScaler\n",
    "from tpot.builtins import ZeroCount\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_up_phone_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.5311752821143861\n",
    "    exported_pipeline = make_pipeline(\n",
    "        RobustScaler(),\n",
    "        MaxAbsScaler(),\n",
    "        ZeroCount(),\n",
    "        ZeroCount(),\n",
    "        RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_features=0.8,\n",
    "                               min_samples_leaf=20, min_samples_split=18, n_estimators=100)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_swipe_up_phone_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swipe-Down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'swipe'\n",
    "device_type = 'phone'\n",
    "direction = 'swipe-down'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "def get_swipe_down_phone_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.7119592629576972\n",
    "    exported_pipeline = SGDClassifier(\n",
    "        alpha=0.001,\n",
    "        eta0=1.0,\n",
    "        fit_intercept=False,\n",
    "        l1_ratio=0.5,\n",
    "        learning_rate=\"invscaling\",\n",
    "        loss=\"modified_huber\",\n",
    "        penalty=\"elasticnet\",\n",
    "        power_t=0.0\n",
    "    )\n",
    "    # Fix random state in exported estimator\n",
    "    if hasattr(exported_pipeline, 'random_state'):\n",
    "        setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_swipe_down_phone_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swipe-Left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'swipe'\n",
    "device_type = 'phone'\n",
    "direction = 'swipe-left'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_left_phone_best_model_f1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.80747694897343\n",
    "    exported_pipeline = make_pipeline(\n",
    "        RFE(\n",
    "            estimator=ExtraTreesClassifier(\n",
    "                criterion=\"gini\",\n",
    "                max_features=0.6500000000000001,\n",
    "                n_estimators=100\n",
    "            ),\n",
    "            step=0.6000000000000001\n",
    "        ),\n",
    "        ExtraTreesClassifier(\n",
    "            bootstrap=True,\n",
    "            criterion=\"entropy\",\n",
    "            max_features=0.6500000000000001,\n",
    "            min_samples_leaf=10,\n",
    "            min_samples_split=4,\n",
    "            n_estimators=100\n",
    "        )\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_left_phone_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.639027759317193\n",
    "    exported_pipeline = make_pipeline(\n",
    "        Binarizer(threshold=0.2),\n",
    "        LinearSVC(C=0.1, dual=True, loss=\"hinge\", penalty=\"l2\", tol=0.001)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_swipe_left_phone_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swipe-Right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'swipe'\n",
    "device_type = 'phone'\n",
    "direction = 'swipe-right'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "def get_swipe_right_phone_best_modelf1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.827952604459662\n",
    "    exported_pipeline = GradientBoostingClassifier(\n",
    "        learning_rate=0.1,\n",
    "        max_depth=1,\n",
    "        max_features=0.15000000000000002,\n",
    "        min_samples_leaf=15,\n",
    "        min_samples_split=4,\n",
    "        n_estimators=100,\n",
    "        subsample=0.4\n",
    "    )\n",
    "    # Fix random state in exported estimator\n",
    "    if hasattr(exported_pipeline, 'random_state'):\n",
    "        setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_right_phone_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.49414250024413603\n",
    "    exported_pipeline = make_pipeline(\n",
    "        MaxAbsScaler(),\n",
    "        GradientBoostingClassifier(learning_rate=0.5, max_depth=2, max_features=0.05,\n",
    "                                   min_samples_leaf=5, min_samples_split=2, n_estimators=100, subsample=0.45)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_swipe_right_phone_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tablet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swipe-Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'swipe'\n",
    "device_type = 'tablet'\n",
    "direction = 'swipe-up'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_up_tablet_best_model_f1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.7582855323691322\n",
    "    exported_pipeline = make_pipeline(\n",
    "        MinMaxScaler(),\n",
    "        GradientBoostingClassifier(\n",
    "            learning_rate=0.1,\n",
    "            max_depth=3,\n",
    "            max_features=0.9000000000000001,\n",
    "            min_samples_leaf=15,\n",
    "            min_samples_split=3,\n",
    "            n_estimators=100,\n",
    "            subsample=0.05\n",
    "        )\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tpot.builtins import ZeroCount\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_up_tablet_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.5115469862579808\n",
    "    exported_pipeline = make_pipeline(\n",
    "        MinMaxScaler(),\n",
    "        ZeroCount(),\n",
    "        DecisionTreeClassifier(\n",
    "            criterion=\"entropy\", max_depth=10, min_samples_leaf=5, min_samples_split=3)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_swipe_up_tablet_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swipe-Down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'swipe'\n",
    "device_type = 'tablet'\n",
    "direction = 'swipe-down'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_down_tablet_best_model_f1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.734812466173996\n",
    "    exported_pipeline = make_pipeline(\n",
    "        SelectPercentile(\n",
    "            score_func=f_classif,\n",
    "            percentile=79\n",
    "        ),\n",
    "        GradientBoostingClassifier(\n",
    "            learning_rate=0.5,\n",
    "            max_depth=6,\n",
    "            max_features=0.8,\n",
    "            min_samples_leaf=8,\n",
    "            min_samples_split=4,\n",
    "            n_estimators=100,\n",
    "            subsample=0.5\n",
    "        )\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_down_tablet_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.5059124041231958\n",
    "    exported_pipeline = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        MLPClassifier(alpha=0.01, learning_rate_init=0.01)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_swipe_down_tablet_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swipe-Left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'swipe'\n",
    "device_type = 'tablet'\n",
    "direction = 'swipe-left'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from tpot.builtins import ZeroCount\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_left_tablet_best_model_f1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.7806663705772975\n",
    "    exported_pipeline = make_pipeline(\n",
    "        ZeroCount(),\n",
    "        StandardScaler(),\n",
    "        MaxAbsScaler(),\n",
    "        GradientBoostingClassifier(\n",
    "            learning_rate=0.1,\n",
    "            max_depth=4,\n",
    "            max_features=0.2,\n",
    "            min_samples_leaf=5,\n",
    "            min_samples_split=11,\n",
    "            n_estimators=100,\n",
    "            subsample=0.5\n",
    "        )\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_left_tablet_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.5301799639825902\n",
    "    exported_pipeline = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        GradientBoostingClassifier(learning_rate=0.1, max_depth=4, max_features=0.5,\n",
    "                                   min_samples_leaf=17, min_samples_split=12, n_estimators=100, subsample=0.4)\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_swipe_left_tablet_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swipe-Right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "gesture = 'swipe'\n",
    "device_type = 'tablet'\n",
    "direction = 'swipe-right'\n",
    "\n",
    "# get data\n",
    "df = get_features_df(gesture, device_type, direction)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(device_type=device_type, first_gesture=gesture, first_gesture_direction=direction):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    model = find_best_model_with_tpot(X_train, y_train, groups)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, device_type=device_type,\n",
    "                 first_gesture=gesture, first_gesture_direction=direction)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "\n",
    "def get_swipe_right_tablet_best_model_f1_weighted():\n",
    "\n",
    "    # Average CV score on the training set was: 0.7279588435516136\n",
    "    exported_pipeline = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        RFE(\n",
    "            estimator=ExtraTreesClassifier(\n",
    "                criterion=\"gini\",\n",
    "                max_features=0.7000000000000001,\n",
    "                n_estimators=100\n",
    "            ),\n",
    "            step=0.2\n",
    "        ),\n",
    "        MLPClassifier(\n",
    "            alpha=0.1,\n",
    "            learning_rate_init=0.001\n",
    "        )\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "def get_swipe_right_tablet_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.5454138065024169\n",
    "    exported_pipeline = make_pipeline(\n",
    "        make_union(\n",
    "            FunctionTransformer(copy),\n",
    "            make_pipeline(\n",
    "                make_union(\n",
    "                    FunctionTransformer(copy),\n",
    "                    FunctionTransformer(copy)\n",
    "                ),\n",
    "                SelectPercentile(score_func=f_classif, percentile=17),\n",
    "                PCA(iterated_power=2, svd_solver=\"randomized\")\n",
    "            )\n",
    "        ),\n",
    "        SelectPercentile(score_func=f_classif, percentile=17),\n",
    "        GaussianNB()\n",
    "    )\n",
    "    # Fix random state for all the steps in exported pipeline\n",
    "    set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_swipe_right_tablet_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del gesture, device_type, direction\n",
    "del df\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Gesture Classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def combine_gestures(first_gesture_df, second_gesture_df):\n",
    "\n",
    "    # get gesture types\n",
    "    first_gesture = first_gesture_df['gesture'].iloc[0]\n",
    "    second_gesture = second_gesture_df['gesture'].iloc[0]\n",
    "\n",
    "    # Columns to drop if present\n",
    "    columns_to_drop = ['session_id', 'device_type',\n",
    "                       'tapped', 'age', 'direction', 'orientation']\n",
    "\n",
    "    # Drop columns if they exist in first gesture df\n",
    "    first_gesture_df = first_gesture_df.drop(\n",
    "        columns=[col for col in columns_to_drop if col in first_gesture_df.columns])\n",
    "\n",
    "    # Append suffix to feature columns of first gesture\n",
    "    first_gesture_df = first_gesture_df.rename(\n",
    "        columns=lambda x: x + '_' + first_gesture if x not in ['user_id', 'age_group'] else x)\n",
    "\n",
    "    # Drop columns if they exist in second gesture df\n",
    "    second_gesture_df = second_gesture_df.drop(\n",
    "        columns=[col for col in columns_to_drop if col in second_gesture_df.columns])\n",
    "\n",
    "    # Append suffix to feature columns of second gesture df\n",
    "    second_gesture_df = second_gesture_df.rename(\n",
    "        columns=lambda x: x + '_' + second_gesture if x not in ['user_id', 'age_group'] else x)\n",
    "\n",
    "    # Shuffle both dataframes\n",
    "    first_gesture_df = shuffle(first_gesture_df).reset_index(drop=True)\n",
    "    second_gesture_df = shuffle(second_gesture_df).reset_index(drop=True)\n",
    "\n",
    "    # Merge on 'user_id' column to ensure each row contains a tap and swipe gesture for the same user\n",
    "    combined_df = pd.merge(first_gesture_df, second_gesture_df, how='inner', on=[\n",
    "                           'user_id', 'age_group'])\n",
    "\n",
    "    print(\n",
    "        f\"There are {first_gesture_df.shape[0]} unique {first_gesture} events\")\n",
    "    print(\n",
    "        f\"There are {second_gesture_df.shape[0]} unique {second_gesture} events\")\n",
    "    print(f\"There are {combined_df.shape[0]} combined events\")\n",
    "\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Swipe-Right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-right'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimal model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "def get_tap_and_swipe_right_phone_best_model():\n",
    "\n",
    "    # Average CV score on the training set was: 0.4451174614618043\n",
    "    exported_pipeline = SGDClassifier(alpha=0.001, eta0=1.0, fit_intercept=True, l1_ratio=1.0,\n",
    "                                      learning_rate=\"constant\", loss=\"squared_hinge\", penalty=\"elasticnet\", power_t=0.5)\n",
    "    # Fix random state in exported estimator\n",
    "    if hasattr(exported_pipeline, 'random_state'):\n",
    "        setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "    return exported_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit optimal model\n",
    "model = get_tap_and_swipe_right_phone_best_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions from test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze optimal model\n",
    "show_accuracy(y_test, y_pred)\n",
    "show_confusion_matrix(y_test, y_pred)\n",
    "show_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del device_type\n",
    "del X_train, X_test, y_train, y_test, groups\n",
    "del model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Swipe-Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-left'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Swipe-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-up'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Swipe-Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-down'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Zoom-In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'zoom'\n",
    "second_gesture_direction = 'zoom-in'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Zoom-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'zoom'\n",
    "second_gesture_direction = 'zoom-out'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom-In and Zoom-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'zoom'\n",
    "first_gesture_direction = 'zoom-in'\n",
    "second_gesture = 'zoom'\n",
    "second_gesture_direction = 'zoom-out'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swipe-Left and Swipe-Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-left'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-right'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swipe-Up and Swipe-Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-up'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-down'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Taps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'tap'\n",
    "second_gesture_direction = None\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Swipe-Rights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-right'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-right'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Swipe-Lefts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-left'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-left'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Swipe-Ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-up'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-up'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Swipe-Downs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-down'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-down'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Zoom-Ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'zoom'\n",
    "first_gesture_direction = 'zoom-in'\n",
    "second_gesture = 'zoom'\n",
    "second_gesture_direction = 'zoom-in'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Zoom-Outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'phone'\n",
    "first_gesture = 'zoom'\n",
    "first_gesture_direction = 'zoom-out'\n",
    "second_gesture = 'zoom'\n",
    "second_gesture_direction = 'zoom-out'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Swipe-Right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-right'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Swipe-Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-left'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Swipe-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-up'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Swipe-Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-down'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Zoom-In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'zoom'\n",
    "second_gesture_direction = 'zoom-in'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap and Zoom-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'zoom'\n",
    "second_gesture_direction = 'zoom-out'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom-In and Zoom-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'zoom'\n",
    "first_gesture_direction = 'zoom-in'\n",
    "second_gesture = 'zoom'\n",
    "second_gesture_direction = 'zoom-out'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swipe-Left and Swipe-Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-left'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-right'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swipe-Up and Swipe-Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-up'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-down'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Taps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'tap'\n",
    "first_gesture_direction = None\n",
    "second_gesture = 'tap'\n",
    "second_gesture_direction = None\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Swipe-Rights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-right'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-right'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Swipe-Lefts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-left'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-left'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Swipe-Ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-up'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-up'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Swipe-Downs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'swipe'\n",
    "first_gesture_direction = 'swipe-down'\n",
    "second_gesture = 'swipe'\n",
    "second_gesture_direction = 'swipe-down'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Zoom-Ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'zoom'\n",
    "first_gesture_direction = 'zoom-in'\n",
    "second_gesture = 'zoom'\n",
    "second_gesture_direction = 'zoom-in'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Zoom-Outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "device_type = 'tablet'\n",
    "first_gesture = 'zoom'\n",
    "first_gesture_direction = 'zoom-out'\n",
    "second_gesture = 'zoom'\n",
    "second_gesture_direction = 'zoom-out'\n",
    "\n",
    "# get data\n",
    "first_gesture_df = get_features_df(\n",
    "    first_gesture, device_type, first_gesture_direction)\n",
    "second_gesture_df = get_features_df(\n",
    "    second_gesture, device_type, second_gesture_direction)\n",
    "df = combine_gestures(first_gesture_df, second_gesture_df)\n",
    "del first_gesture_df, second_gesture_df\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, groups = train_test_split_on_users(df)\n",
    "del df\n",
    "verify_users(X_train, X_test)\n",
    "plot_train_test_sample_split(X_train, X_test)\n",
    "report_train_test_sample_split(X_train, X_test)\n",
    "\n",
    "# remove unnused columns\n",
    "X_train = remove_columns(X_train)\n",
    "X_test = remove_columns(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the exported model exists before running TPOT\n",
    "if not exported_model_exists(first_gesture=first_gesture, first_gesture_direction=first_gesture_direction, second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type):\n",
    "    print(\"Exported model not found. Running Tree-based Pipeline Optimization Tool (TPOT)...\")\n",
    "\n",
    "    # find optimal pipeline, model, and hyperparameters with training data\n",
    "    # override generations and population size for shorter runtime\n",
    "    model = find_best_model_with_tpot(\n",
    "        X_train, y_train, groups=groups, generations=5, population_size=50)\n",
    "\n",
    "    # export optimal model\n",
    "    export_model(model=model, first_gesture=first_gesture, first_gesture_direction=first_gesture_direction,\n",
    "                 second_gesture=second_gesture, second_gesture_direction=second_gesture_direction, device_type=device_type)\n",
    "\n",
    "else:\n",
    "    print(\"Exported model found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
